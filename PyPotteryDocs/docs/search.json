[
  {
    "objectID": "pypotteryink/index.html",
    "href": "pypotteryink/index.html",
    "title": "Introduction",
    "section": "",
    "text": "version 2.0.0\n  \n\n  \n    \n    \n    \n      \n      \n        CPU\n      \n    \n\n    \n    \n      \n      \n        CUDA\n      \n    \n\n    \n    \n      \n      \n        MPS\nPyPotteryInk is a specialized tool designed for processing and enhancing pottery drawings. It streamlines the workflow of diagnostic, preprocessing, and batch processing of archaeological illustrations.",
    "crumbs": [
      "PyPotteryInk",
      "Introduction"
    ]
  },
  {
    "objectID": "pypotteryink/index.html#key-features",
    "href": "pypotteryink/index.html#key-features",
    "title": "Introduction",
    "section": "Key Features",
    "text": "Key Features\n\n‚öôÔ∏è Hardware Check: Analyze your system capabilities to ensure optimal performance.\nüîç Model Diagnostic: Test models on single images to fine-tune parameters before batch processing.\nüìä Preprocessing: Calculate and apply statistical adjustments to standardize your images.\nüé® Batch Processing: Process large sets of images with advanced AI models for enhancement and restoration.",
    "crumbs": [
      "PyPotteryInk",
      "Introduction"
    ]
  },
  {
    "objectID": "pypotteryink/index.html#contributors",
    "href": "pypotteryink/index.html#contributors",
    "title": "Introduction",
    "section": "Contributors",
    "text": "Contributors\n\n  \n    \n      \n    \n    \n    Lorenzo Cardarelli\n  \n  \n    \n      \n    \n    \n    Enzo Cocca\n  \n    \n    \n      \n    \n    \n    Francesco Di Filippo",
    "crumbs": [
      "PyPotteryInk",
      "Introduction"
    ]
  },
  {
    "objectID": "pypotteryscan/usage.html",
    "href": "pypotteryscan/usage.html",
    "title": "Using PyPotteryScan",
    "section": "",
    "text": "version 0.2.0",
    "crumbs": [
      "PyPotteryScan",
      "Using PyPotteryScan"
    ]
  },
  {
    "objectID": "pypotteryscan/usage.html#creating-a-new-project",
    "href": "pypotteryscan/usage.html#creating-a-new-project",
    "title": "Using PyPotteryScan",
    "section": "Creating a New Project",
    "text": "Creating a New Project\n\nClick the ‚ÄúNew Project‚Äù button.\nEnter a name for your project.\n(Optional) Add a description.\nClick ‚ÄúCreate‚Äù. You can create a new project by clicking on ‚ûï New Project or ‚ûï Create First Project if you don‚Äôt have any projects yet (Figure¬†1)\n\n\n\n\n\n\n\nFigure¬†1\n\n\n\nOnce the project is created and information such as name and description is added, the program moves to the Load tab where you can select the folder containing the images to process (Figure¬†2).\n\n\n\n\n\n\nFigure¬†2\n\n\n\nA loading screen will show the progress of the image import (Figure¬†3).\n\n\n\n\n\n\nFigure¬†3\n\n\n\nThe imported images will be visible in the Load tab (Figure¬†4).\n\n\n\n\n\n\nFigure¬†4\n\n\n\nClicking on Start Annotation ‚Üí will start the scanning process and take you to the Annotate tab.\n\nProject Structure\nFor reference, PyPotteryScan projects are stored in the projects directory with the following structure:\nproject_id/\n‚îú‚îÄ‚îÄ original_images/    # Source scans\n‚îú‚îÄ‚îÄ thumbnails/         # Cached thumbnails\n‚îú‚îÄ‚îÄ annotations/        # JSON annotation files\n‚îú‚îÄ‚îÄ cropped_drawings/   # Intermediate crops\n‚îú‚îÄ‚îÄ cleaned_drawings/   # Cleaned images\n‚îú‚îÄ‚îÄ ocr_results/        # OCR JSON data\n‚îú‚îÄ‚îÄ exports/            # Export history\n‚îú‚îÄ‚îÄ fewshot_examples/   # Saved training examples\n‚îî‚îÄ‚îÄ project.json        # Project metadata",
    "crumbs": [
      "PyPotteryScan",
      "Using PyPotteryScan"
    ]
  },
  {
    "objectID": "pypotteryscan/usage.html#gui-elements",
    "href": "pypotteryscan/usage.html#gui-elements",
    "title": "Using PyPotteryScan",
    "section": "GUI Elements",
    "text": "GUI Elements\nThe tab is dominated by the canvas where the plates are visualized. Above it, the number of plates and navigation buttons are indicated (Figure¬†5). The + Drawing button allows you to create a new annotation, while the Clear button deletes all annotations created on the plate.\nOn the right, there are text boxes indicating information related to the plate such as name (filename), a free field for context, and notes. The üíæ Save Metadata button allows you to save the inserted information.\nBelow, there are summary boxes for the created annotations.\nThe Finish & Process OCR ‚Üí button allows you to save the annotations and proceed to the Process OCR tab.\n\n\n\n\n\n\nFigure¬†5",
    "crumbs": [
      "PyPotteryScan",
      "Using PyPotteryScan"
    ]
  },
  {
    "objectID": "pypotteryscan/usage.html#creating-annotations",
    "href": "pypotteryscan/usage.html#creating-annotations",
    "title": "Using PyPotteryScan",
    "section": "Creating Annotations",
    "text": "Creating Annotations\nTo create a new annotation, click on the + Drawing button. A window will alert the user to select a rectangular area on the plate (Figure¬†6).\nAnnotations are of two types: ‚ÄúDrawing‚Äù and ‚ÄúText‚Äù. The first is used to select areas with drawings, the second to select areas with text.\nOnce the selection is complete, the selected area will be highlighted and added to the list of annotations.\n\n\n\n\n\n\nFigure¬†6\n\n\n\nInside Drawings, it is possible to add text. A window will alert the user to insert the text associated with the drawing.\nTo delete a text annotation, you can click on the ‚ùå button next to the annotation in the list (Figure¬†7).\n\n\n\n\n\n\nFigure¬†7\n\n\n\nTo add a new image annotation, click again on the + Drawing button and repeat the process.\nIt is possible to add multiple text annotations for each drawing by clicking again on the + Text button inside the drawing annotation (Figure¬†8).\n\n\n\n\n\n\nFigure¬†8\n\n\n\nClicking on Finish & Process OCR ‚Üí will save the annotations and move to the Process OCR tab.",
    "crumbs": [
      "PyPotteryScan",
      "Using PyPotteryScan"
    ]
  },
  {
    "objectID": "pypotteryscan/usage.html#gui-elements-1",
    "href": "pypotteryscan/usage.html#gui-elements-1",
    "title": "Using PyPotteryScan",
    "section": "GUI Elements",
    "text": "GUI Elements\nIn the center of the tab is the canvas with the extracted image. Above are the navigation buttons and the total number of drawings. On the right are some commands for cleaning the image (Figure¬†11).\nImmediately above the canvas are text boxes showing information related to the drawing, and a slider for the eraser size.\nBelow the canvas is a gallery showing all images.\n\n\n\n\n\n\nFigure¬†11",
    "crumbs": [
      "PyPotteryScan",
      "Using PyPotteryScan"
    ]
  },
  {
    "objectID": "pypotteryscan/usage.html#cleaning-tools",
    "href": "pypotteryscan/usage.html#cleaning-tools",
    "title": "Using PyPotteryScan",
    "section": "Cleaning Tools",
    "text": "Cleaning Tools\nTo clean an image, an eraser is available which can be adjusted in size via the slider above the canvas. In the example, the number 1 present in the image has been removed (Figure¬†12).\n\n\n\n\n\n\nFigure¬†12\n\n\n\nClick on the navigation button, as well as on ‚úì Mark as Clean, or click on the preview in the gallery to save the cleaned image and move to the next drawing.\nA green checkmark will indicate that the image has been manually reviewed (Figure¬†13).\n\n\n\n\n\n\nFigure¬†13\n\n\n\nClick on Continue to Review Texts ‚Üí to save the cleaned images and proceed to the Review Texts tab.\n\n\n\n\n\n\nImportant\n\n\n\nAt this stage, eraser can‚Äôt show a brush preview on hover. The feature will be added in future releases.",
    "crumbs": [
      "PyPotteryScan",
      "Using PyPotteryScan"
    ]
  },
  {
    "objectID": "pypotteryscan/usage.html#review-texts",
    "href": "pypotteryscan/usage.html#review-texts",
    "title": "Using PyPotteryScan",
    "section": "Review Texts",
    "text": "Review Texts\nThis tab allows you to review and correct the text extracted via OCR (Figure¬†14).\n\n\n\n\n\n\n\n\nFigure¬†14\n\n\n\nThe interface is extremely simple: a series of bipartite records where on the left we find the image of the text area and on the right the extracted text in an editable text box. Just write inside the box to correct the text.\nTo see the image better, you can hover the mouse over the image to enlarge it; clicking on the image will open a modal window with the enlarged image {Figure¬†15}.\n\n\n\n\n\n\nFigure¬†15\n\n\n\nClick on Continue to Export ‚Üí to save changes and proceed to the Export tab.",
    "crumbs": [
      "PyPotteryScan",
      "Using PyPotteryScan"
    ]
  },
  {
    "objectID": "pypotteryscan/usage.html#exported-folder-structure",
    "href": "pypotteryscan/usage.html#exported-folder-structure",
    "title": "Using PyPotteryScan",
    "section": "Exported Folder Structure",
    "text": "Exported Folder Structure\nInside the exported folder, you will find the following structure:\n[Selected Folder]/\n‚îú‚îÄ‚îÄ images/                                 # Folder containing cropped drawings\n‚îÇ   ‚îú‚îÄ‚îÄ {prefix}_001.jpg                    # Individual drawing images\n‚îÇ   ‚îú‚îÄ‚îÄ {prefix}_002.jpg\n‚îÇ   ‚îî‚îÄ‚îÄ ...\n‚îú‚îÄ‚îÄ {prefix}_data_{timestamp}.xlsx          # Excel file with Metadata and OCR results\n‚îî‚îÄ‚îÄ {prefix}_ml_training_{timestamp}.xlsx   # Excel file with Bounding Box data for ML\nThe Data Excel contains:\n\nfilename: Name of the cropped image file\noriginal_image: Source plate filename\ndrawing_number: ID of the drawing\ntable_name, context, notes: Metadata\nocr_result: Raw OCR text\nocr_corrected: Manually corrected text\n\nThe ML Training Excel contains bounding box coordinates for vessels and text areas, useful for training machine learning models.",
    "crumbs": [
      "PyPotteryScan",
      "Using PyPotteryScan"
    ]
  },
  {
    "objectID": "pypotteryscan/usage.html#gui-elements-2",
    "href": "pypotteryscan/usage.html#gui-elements-2",
    "title": "Using PyPotteryScan",
    "section": "GUI Elements",
    "text": "GUI Elements\nOn the left of the tab are Available fields representing the fields that can be identified in the text. The + Add Field button allows you to add a new custom field (Figure¬†17).\nOn the right are a series of commands that allow you to configure the parser.\n\n\n\n\n\n\nFigure¬†17\n\n\n\nThe üìÇ Select Files button allows you to select the .xlsx file exported from the Export tab. The model will look for an ‚Äúocr_corrected‚Äù column.\nThe content of the ‚Äúocr_corrected‚Äù column will be displayed in the text box. By selecting the text, you can associate the available fields (Figure¬†18).\n\n\n\n\n\n\nFigure¬†18\n\n\n\nClicking on ‚ûï Add Example will allow you to add an example of association between text and fields (Figure¬†19).\n\n\n\n\n\n\nFigure¬†19\n\n\n\nClicking on üöÄ Run Parsing will start the parsing process. A progress bar will show the advancement of the process. Once processing is finished, a dialog window will allow you to save the exported file in .xlsx format (Figure¬†20).\n\n\n\n\n\n\nFigure¬†20",
    "crumbs": [
      "PyPotteryScan",
      "Using PyPotteryScan"
    ]
  },
  {
    "objectID": "pypotteryscan/usage.html#load-a-project",
    "href": "pypotteryscan/usage.html#load-a-project",
    "title": "Using PyPotteryScan",
    "section": "Load a Project",
    "text": "Load a Project\nIf you want to load an existing project, you can do so from the initial screen by clicking on üìÇ Load Project (Figure¬†21).\n\n\n\n\n\n\nFigure¬†21\n\n\n\nEach project will be listed as a card, with information such as name, description, creation date, and last modification date, as well as the number of uploaded images and created annotations, along with a progress bar indicating the project‚Äôs completion status.\nThe üóëÔ∏è (trash can) icon next to each project allows you to delete the selected project.\n\n\n\n\n\n\nCaution\n\n\n\nCaution: Deleting a project is irreversible and will permanently remove all associated data.\n\n\nOpening a project allows you to resume work exactly where it was left off. Even if the Load tab is opened, you will be able to navigate between other tabs to complete the workflow (Figure¬†22).\n\n\n\n\n\n\nFigure¬†22\n\n\n\nThe Load table will show the images loaded within the project, as well as the annotations created. Click on the preview to open the Annotate tab on that specific image.",
    "crumbs": [
      "PyPotteryScan",
      "Using PyPotteryScan"
    ]
  },
  {
    "objectID": "pypotteryscan/index.html",
    "href": "pypotteryscan/index.html",
    "title": "Introduction",
    "section": "",
    "text": "version 0.2.0\n  \n\n  \n    \n    \n    \n      \n      \n        CPU (Not Supported)\n      \n    \n\n    \n    \n      \n      \n        CUDA (Supported)\n      \n    \n\n    \n    \n      \n      \n        MPS (Coming Soon)\nPyPotteryScan is a specialized tool designed for digitizing and processing scanned pottery plates. It streamlines the workflow of extracting drawings, recognizing text (OCR), and structuring data.",
    "crumbs": [
      "PyPotteryScan",
      "Introduction"
    ]
  },
  {
    "objectID": "pypotteryscan/index.html#key-features",
    "href": "pypotteryscan/index.html#key-features",
    "title": "Introduction",
    "section": "Key Features",
    "text": "Key Features\n\nüìÇ Project Management: Organize your work in portable, self-contained project folders.\n‚úèÔ∏è Annotation & OCR: Easily select drawings and text on plates, using automated OCR to digitize handwritten notes.\nüßπ Image Cleaning: Integrated tools to clean and refine extracted drawing images.\nüìù Data Review & Parsing: Verify OCR results and use the Few-Shot Parser (LLM) to structure free text into data fields.\nüì¶ Structured Export: Export everything into organized folders with Excel reports for easy analysis.",
    "crumbs": [
      "PyPotteryScan",
      "Introduction"
    ]
  },
  {
    "objectID": "pypotteryscan/index.html#contributors",
    "href": "pypotteryscan/index.html#contributors",
    "title": "Introduction",
    "section": "Contributors",
    "text": "Contributors\n\n  \n    \n      \n    \n    \n    Lorenzo Cardarelli",
    "crumbs": [
      "PyPotteryScan",
      "Introduction"
    ]
  },
  {
    "objectID": "pypotterylens/usage.html",
    "href": "pypotterylens/usage.html",
    "title": "Using PyPotteryLens",
    "section": "",
    "text": "version 0.2.0",
    "crumbs": [
      "PyPotteryLens",
      "Using PyPotteryLens"
    ]
  },
  {
    "objectID": "pypotterylens/usage.html#project-manager",
    "href": "pypotterylens/usage.html#project-manager",
    "title": "Using PyPotteryLens",
    "section": "Project Manager",
    "text": "Project Manager\nLike other tools in the PyPottery suite, PyPotteryLens uses a project management system.\nYou can create a project by entering a name in the text box, along with an optional description and an icon.\nOnce created, the project will appear in the ‚ÄúYour Projects‚Äù list.\nSelecting a project will display its name in the status bar.",
    "crumbs": [
      "PyPotteryLens",
      "Using PyPotteryLens"
    ]
  },
  {
    "objectID": "pypotterylens/usage.html#pdf-document-processing",
    "href": "pypotterylens/usage.html#pdf-document-processing",
    "title": "Using PyPotteryLens",
    "section": "PDF Document Processing",
    "text": "PDF Document Processing\nIn this tab, you can upload and process a PDF file, transforming it into a series of images.\n\n\nClicking on Upload PDF to current project will open a dialog window to select the PDF file.\n\n\n\n\n\n\nImportant\n\n\n\nThe Split Scanned checkbox must be checked BEFORE selecting the file if the PDF to be processed has 2 pages side-by-side.\n\n\nOnce the PDF is processed, you can proceed to the next tab.",
    "crumbs": [
      "PyPotteryLens",
      "Using PyPotteryLens"
    ]
  },
  {
    "objectID": "pypotterylens/usage.html#apply-model",
    "href": "pypotterylens/usage.html#apply-model",
    "title": "Using PyPotteryLens",
    "section": "Apply Model",
    "text": "Apply Model\nIn this tab, you can use the Computer Vision (CV) model to extract information.\n\n\n\nGUI Layout\nThe GUI is divided into two parts:\n\nRight Side: A gallery containing the images. Clicking on an image opens it in full screen. In the top right of each image, there is an icon that allows you to exclude the page from processing. To re-include an image, simply click the checkmark again.\nLeft Side: Contains the model parameters.\n\n\n\nParameters\n\nModel Selection: Allows you to select the model to apply.\nModel Parameters: You can define the confidence threshold for the model as well as some post-processing operations for the masks.\nAdvanced Options: Includes the possibility to limit the application to 25 pages for debugging purposes.\n\nOnce you click on üöÄ Apply Model to Project, a progress bar will indicate the status of the process.\n\n\n\n\n\n\nNote\n\n\n\nTo use a different model, place it in the appropriate folder.",
    "crumbs": [
      "PyPotteryLens",
      "Using PyPotteryLens"
    ]
  },
  {
    "objectID": "pypotterylens/usage.html#review-annotations",
    "href": "pypotterylens/usage.html#review-annotations",
    "title": "Using PyPotteryLens",
    "section": "Review Annotations",
    "text": "Review Annotations\nIn this tab, you can review and modify the model‚Äôs annotations.\n\n\n\nLeft: A list of files indicating the pages.\nRight: A canvas showing the image.\n\nYou can navigate between images by selecting the name or using the buttons below the image.\nIn the list: - Green Checkmark: Images where the model has identified vases. - White Dot: Images where the model has not recognized any vases.\n\nEditing Masks\nYou can modify the masks identified by the model using the buttons below the canvas: - üñåÔ∏è Brush: To draw new masks. - üßπ Eraser: To delete existing masks. - üóëÔ∏è Clear: To delete all masks.\nNew masks will appear in red.\nOnce an image without masks (white dot) is modified, the indicator will update to a green checkmark.\nChanging the image or clicking on üíæ Save Current Mask will save the changes.\nOnce you have reviewed the images, you can extract them by clicking on üì§ Extract Cards.",
    "crumbs": [
      "PyPotteryLens",
      "Using PyPotteryLens"
    ]
  },
  {
    "objectID": "pypotterylens/usage.html#tabular-information",
    "href": "pypotterylens/usage.html#tabular-information",
    "title": "Using PyPotteryLens",
    "section": "Tabular Information",
    "text": "Tabular Information\nThis tab allows you to insert tabular information for the images.\n\n\n\nCenter: A canvas displaying the image where each identified element is associated with a bounding box and an ID.\nLeft: A file list for navigation.\nRight: A table where you can enter tabular information.\n\nEach record is indicated by an ID visible on the canvas. To add a column, write the name and click ‚ûï Add Column. Once the information is entered, you can click on üëÅÔ∏è Mark as Reviewed. The inserted columns are persistent across the project‚Äôs images.",
    "crumbs": [
      "PyPotteryLens",
      "Using PyPotteryLens"
    ]
  },
  {
    "objectID": "pypotterylens/usage.html#post-processing",
    "href": "pypotterylens/usage.html#post-processing",
    "title": "Using PyPotteryLens",
    "section": "Post Processing",
    "text": "Post Processing\nFinally, you can post-process the images to standardize them (e.g., profile on the right and rim facing upwards).\n\n\n\nGUI Layout\n\nLeft: List of images, processing options, and navigation buttons.\nRight: A double canvas (initially only the left one is active).\n\n\n\nWorkflow\nTo start post-processing, click on üîç Process All Images. The model will highlight the position and conservation status of the pieces. The positioned vase will appear in ‚ÄúProcessed Image‚Äù.\nYou can navigate through the records using the buttons and the file list.\nIf the model has misclassified a vase, you can manually modify the classification.\nYou can also set image transformations to lock specific transformations.\nOnce post-processing is complete, click on üì¶ Export Results to save the images in a ZIP folder.\nAn Excel file (.xlsx) containing the previously added tabular information will be exported along with the images.",
    "crumbs": [
      "PyPotteryLens",
      "Using PyPotteryLens"
    ]
  },
  {
    "objectID": "pypotterylens/index.html",
    "href": "pypotterylens/index.html",
    "title": "Introduction",
    "section": "",
    "text": "version 0.2.0\n  \n  \n  \n    \n    \n    \n      \n      \n        CPU\n      \n    \n\n    \n    \n      \n      \n        CUDA\n      \n    \n\n    \n    \n      \n      \n        MPS\n      \n    \n\n\n\n\n\n\nPyPotteryLens is a tool designed for the extraction and processing of pottery images from PDF documents. It streamlines the workflow of extracting drawings, applying computer vision models, and structuring the data for analysis.\n\n\n\nüìÇ Project Management: Organize your work in portable, self-contained project folders.\nüìÑ PDF Processing: Convert PDF documents into processable images.\nü§ñ Apply Model: Use Computer Vision models to extract information and masks from images.\n‚úèÔ∏è Review Annotations: Review and modify the masks identified by the model.\nüìä Tabular Information: Associate tabular data with identified elements.\nüîÑ Post Processing: Standardize images (orientation, positioning) and export results.\n\n\n\n\n\n\n&lt;a href=\"https://github.com/lrncrd\" target=\"_blank\"&gt;\n  &lt;img src=\"https://github.com/lrncrd.png\" alt=\"Lorenzo Cardarelli\" style=\"border-radius: 50%; width: 80px; height: 80px; object-fit: cover; border: 1px solid #e1e4e8;\"&gt;\n&lt;/a&gt;\n&lt;br&gt;\n&lt;span style=\"font-size: 0.9em; font-weight: 600; color: #24292e;\"&gt;Lorenzo Cardarelli&lt;/span&gt;\n\n\n&lt;a href=\"https://github.com/enzococca\" target=\"_blank\"&gt;\n  &lt;img src=\"https://github.com/enzococca.png\" alt=\"Enzo Cocca\" style=\"border-radius: 50%; width: 80px; height: 80px; object-fit: cover; border: 1px solid #e1e4e8;\"&gt;\n&lt;/a&gt;\n&lt;br&gt;\n&lt;span style=\"font-size: 0.9em; font-weight: 600; color: #24292e;\"&gt;Enzo Cocca&lt;/span&gt;\n\n&lt;div style=\"text-align: center;\"&gt;\n&lt;a href=\"https://github.com/pankus\" target=\"_blank\"&gt;\n  &lt;img src=\"https://github.com/pankus.png\" alt=\"Francesco Di Filippo\" style=\"border-radius: 50%; width: 80px; height: 80px; object-fit: cover; border: 1px solid #e1e4e8;\"&gt;\n&lt;/a&gt;\n&lt;br&gt;\n&lt;span style=\"font-size: 0.9em; font-weight: 600; color: #24292e;\"&gt;PanKus&lt;/span&gt;",
    "crumbs": [
      "PyPotteryLens",
      "Introduction"
    ]
  },
  {
    "objectID": "pypotterylens/index.html#key-features",
    "href": "pypotterylens/index.html#key-features",
    "title": "Introduction",
    "section": "",
    "text": "üìÇ Project Management: Organize your work in portable, self-contained project folders.\nüìÑ PDF Processing: Convert PDF documents into processable images.\nü§ñ Apply Model: Use Computer Vision models to extract information and masks from images.\n‚úèÔ∏è Review Annotations: Review and modify the masks identified by the model.\nüìä Tabular Information: Associate tabular data with identified elements.\nüîÑ Post Processing: Standardize images (orientation, positioning) and export results.",
    "crumbs": [
      "PyPotteryLens",
      "Introduction"
    ]
  },
  {
    "objectID": "pypotterylens/index.html#contributors",
    "href": "pypotterylens/index.html#contributors",
    "title": "Introduction",
    "section": "",
    "text": "&lt;a href=\"https://github.com/lrncrd\" target=\"_blank\"&gt;\n  &lt;img src=\"https://github.com/lrncrd.png\" alt=\"Lorenzo Cardarelli\" style=\"border-radius: 50%; width: 80px; height: 80px; object-fit: cover; border: 1px solid #e1e4e8;\"&gt;\n&lt;/a&gt;\n&lt;br&gt;\n&lt;span style=\"font-size: 0.9em; font-weight: 600; color: #24292e;\"&gt;Lorenzo Cardarelli&lt;/span&gt;\n\n\n&lt;a href=\"https://github.com/enzococca\" target=\"_blank\"&gt;\n  &lt;img src=\"https://github.com/enzococca.png\" alt=\"Enzo Cocca\" style=\"border-radius: 50%; width: 80px; height: 80px; object-fit: cover; border: 1px solid #e1e4e8;\"&gt;\n&lt;/a&gt;\n&lt;br&gt;\n&lt;span style=\"font-size: 0.9em; font-weight: 600; color: #24292e;\"&gt;Enzo Cocca&lt;/span&gt;\n\n&lt;div style=\"text-align: center;\"&gt;\n&lt;a href=\"https://github.com/pankus\" target=\"_blank\"&gt;\n  &lt;img src=\"https://github.com/pankus.png\" alt=\"Francesco Di Filippo\" style=\"border-radius: 50%; width: 80px; height: 80px; object-fit: cover; border: 1px solid #e1e4e8;\"&gt;\n&lt;/a&gt;\n&lt;br&gt;\n&lt;span style=\"font-size: 0.9em; font-weight: 600; color: #24292e;\"&gt;PanKus&lt;/span&gt;",
    "crumbs": [
      "PyPotteryLens",
      "Introduction"
    ]
  },
  {
    "objectID": "pypotteryink/usage.html",
    "href": "pypotteryink/usage.html",
    "title": "Using PyPotteryInk",
    "section": "",
    "text": "version 2.0.0 \n\n\nInterface Overview\nThe PyPotteryInk interface is divided into four main tabs:\n\nHardware Check\nModel Diagnostic\nPreprocessing\nBatch Processing\n\nAdditionally, you can toggle Dark Mode using the button in the interface.\n\n\nHardware Check\nThis tab allows you to analyze your PC‚Äôs hardware to verify compatibility with PyPotteryInk.\n\n\nThe page displays Recommended Specifications, indicating the minimum requirements to use the program.\nClicking on üîç Check Hardware will display your machine‚Äôs specifications along with a performance score.\nHere is an example of a hardware check result on a MacBook Air M3:\n\n\n\n\n\n\nüü† Recommendation Level: RECOMMENDED\n\n\n\n\nüñ•Ô∏è Hardware Specifications\n\nGPU: Apple Metal Performance Shaders (MPS)\nCPU: arm (8 cores)\nRAM: 16.0 GB\nDisk speed: Read: 5931.6 MB/s | Write: 233.8 MB/s\n\n\n\nüìä Hardware Score: 78/100 (78.0%)\n\n\nüí° Recommendations\n\n‚úÖ Apple Metal Performance Shaders (MPS) - Excellent acceleration for Apple Silicon\n‚úÖ 16GB or more RAM - Ideal for large image batches\n‚ö†Ô∏è Processor with 4+ cores\n‚ö†Ô∏è Decent disk but could be improved with an NVMe SSD\n‚úÖ macOS system - Good compatibility\nüí° If using a laptop, ensure it‚Äôs well ventilated and connected to power\nüí° Consider using a cooling pad for laptops to avoid thermal throttling\n\n\n\n‚úÖ Conclusion\nYour hardware is adequate for using PyPotteryInk, but you may encounter some limitations with very large images.\nüí° If you‚Äôre using a laptop, ensure it‚Äôs well ventilated and connected to power during processing\n\n\n\n\n\nModel Diagnostic\nThis tab allows you to test the model on a single image to verify its operation and determine the best parameters for batch processing.\n\n\nThe available elements are:\n\nSelect Model: Allows you to select the model to use (see the Model Zoo section for details). The model will be automatically downloaded during processing.\nPatch Size: Determines the size of the ‚Äúchunks‚Äù the image is divided into for processing. Refer to the dedicated documentation section.\nUpload Images: This window allows you to upload images. You can use drag-and-drop or a dialog window. Once uploaded, images are displayed as thumbnails.\nOverlap: Determines the number of pixels where patches overlap. Refer to the dedicated documentation section.\nContrast Test Values: The model will generate an enhancement using the indicated values. To add a contrast value for evaluation, separate it with a comma.\n\nClicking on üöÄ Run Diagnostic will start the process, and a progress bar will indicate advancement. At the end of the process, a gallery will allow you to view the results.\n\n\nPreprocessing\nThis tab allows you to process images by adjusting statistics (contrast, etc.) to fit within a range known by the model.\n\n\nThere are two options:\n\nStep 1: Calculate Statistics\nYou can calculate statistics from a set of images. Uploading is done in the same way as the previous tab. The Save Statistics As text box allows you to decide the path and name of the .npy file. Click üìä Calculate Statistics to perform the calculation.\n\n\nStep 2: Apply Preprocessing\nThis step allows you to apply the statistics. Images are uploaded in the same way. A checkbox allows you to use the statistics directly from Step 1. Alternatively, you can use an existing .npy file.\nPyPotteryInk provides two default .npy files:\n\nMontale_stats.npy (Metric measures of the dataset used to train the 6h-MCG model)\nCimino_stats.npy (Metric measures of the dataset used to train the 6h-MC model)\n\nIn short, these metrics can be used to make your images resemble those used to train the model.\nThe Output Directory text box allows you to indicate where the modified images will be saved. Click ‚ú® Apply Preprocessing to start. A progress bar will indicate the status.\n\n\n\nBatch Processing\nThis tab represents the core of the program where you can process a series of images.\n\n\nParameters like Select Model, Upload Images, Patch Size, and Overlap are the same as in the Preprocessing tab.\nNew parameters include:\n\nOutput Directory: Allows you to indicate where to save the results.\nContrast Scale: Allows you to indicate the contrast value to apply to the batch.\nScale Factor: Allows you to temporarily apply upsampling or downsampling to the images. After processing, images will be saved in their original dimensions, so there is no need to rescale them manually.\nUse FP16: Allows you to apply the model using half-precision (requires CUDA).\n\nClicking on üöÄ Start Processing will start the operation. A double progress bar will indicate the processing of patches and drawings. The results will be shown in a gallery.",
    "crumbs": [
      "PyPotteryInk",
      "Using PyPotteryInk"
    ]
  },
  {
    "objectID": "pypotteryink/installation.html",
    "href": "pypotteryink/installation.html",
    "title": "Installation",
    "section": "",
    "text": "version 2.0.0",
    "crumbs": [
      "PyPotteryInk",
      "Installation"
    ]
  },
  {
    "objectID": "pypotteryink/installation.html#requirements",
    "href": "pypotteryink/installation.html#requirements",
    "title": "Installation",
    "section": "Requirements",
    "text": "Requirements\nBefore installing PyPotteryInk, make sure you have:\n\nPython 3.12 installed on your system",
    "crumbs": [
      "PyPotteryInk",
      "Installation"
    ]
  },
  {
    "objectID": "pypotteryink/installation.html#automated-installation",
    "href": "pypotteryink/installation.html#automated-installation",
    "title": "Installation",
    "section": "Automated Installation",
    "text": "Automated Installation\nAutomated installation is the quickest and easiest way to get PyPotteryInk running. The provided scripts will:\n\n‚úÖ Create a Python virtual environment\n‚úÖ Automatically install all dependencies\n‚úÖ Start the application\n\n\nWindows\nDouble click on the PyPotteryInk_WIN.bat file.\nThe script will automatically perform the following steps:\n\nCheck for Python on the system\nCreate the .venv virtual environment (if it doesn‚Äôt exist)\nActivate the virtual environment\nInstall/upgrade pip\nInstall dependencies from requirements.txt\nStart the Flask server at http://localhost:5003\n\n\n\n\n\n\n\nüí° Tip\n\n\n\nOn first run, dependency installation may take a few minutes. Subsequent runs will be much faster!\n\n\n\n\nLinux / macOS\n\nOpen the Terminal in the project directory\nMake the script executable (first time only):\n\nchmod +x PyPotteryInk_UNIX.sh\n\nRun the script:\n\n./PyPotteryInk_UNIX.sh\nThe script will automatically:\n\nCheck for Python 3 on the system\nCreate the .venv virtual environment (if it doesn‚Äôt exist)\nActivate the virtual environment\nInstall/upgrade pip\nInstall dependencies from requirements.txt\nStart the Flask server at http://127.0.0.1:5003\n\n\n\n\n\n\n\nüìå Note\n\n\n\nTo stop the server, press Ctrl+C in the terminal.",
    "crumbs": [
      "PyPotteryInk",
      "Installation"
    ]
  },
  {
    "objectID": "pypotteryink/installation.html#manual-installation",
    "href": "pypotteryink/installation.html#manual-installation",
    "title": "Installation",
    "section": "Manual Installation",
    "text": "Manual Installation\nIf you prefer full control over the installation process, you can follow these manual steps:\n\n1. Create a Virtual Environment\nIt is strongly recommended to use a virtual environment to isolate project dependencies:\n\nWindowsLinux / macOS\n\n\npython -m venv .venv\n.venv\\Scripts\\activate\n\n\npython3 -m venv .venv\nsource .venv/bin/activate\n\n\n\n\n\n2. Upgrade pip\nUpgrade pip to the latest available version:\npython -m pip install --upgrade pip\n\n\n3. Install Dependencies\nInstall all required dependencies from the requirements.txt file:\npip install -r requirements.txt\n\n\n\n\n\n\n‚ö†Ô∏è Warning\n\n\n\nMake sure you are in the project‚Äôs root directory where the requirements.txt file is located.\n\n\n\n\n4. Start the Application\nOnce installation is complete, start the application with:\npython app.py\nThe application will be available at:\n\n\n\n\n\n\nüåê Application URL\n\n\n\nhttp://localhost:5003",
    "crumbs": [
      "PyPotteryInk",
      "Installation"
    ]
  },
  {
    "objectID": "pypotteryink/installation.html#installation-verification",
    "href": "pypotteryink/installation.html#installation-verification",
    "title": "Installation",
    "section": "Installation Verification",
    "text": "Installation Verification\nTo verify that everything was installed correctly:\n\nThe application should start without errors\nYou should see a confirmation message in the terminal\nOpening your browser at http://localhost:5003 should display the PyPotteryInk interface",
    "crumbs": [
      "PyPotteryInk",
      "Installation"
    ]
  },
  {
    "objectID": "pypotteryink/installation.html#troubleshooting",
    "href": "pypotteryink/installation.html#troubleshooting",
    "title": "Installation",
    "section": "Troubleshooting",
    "text": "Troubleshooting\n\nPython not found\nIf you receive an error indicating that Python is not installed:\n\nWindows: Download Python from python.org and make sure to check ‚ÄúAdd Python to PATH‚Äù during installation\nLinux: Install Python using your distribution‚Äôs package manager (e.g., sudo apt install python3)\nmacOS: Install Python via Homebrew with brew install python3\n\n\n\nDependency installation errors\nIf dependency installation fails:\n\nMake sure you have an active internet connection\nTry upgrading pip: python -m pip install --upgrade pip\nInstall dependencies one at a time to identify which package is causing issues\n\n\n\nPort 5003 already in use\nIf port 5003 is already occupied by another application, you can:\n\nClose the application using the port\nOr modify the port in the app.py file",
    "crumbs": [
      "PyPotteryInk",
      "Installation"
    ]
  },
  {
    "objectID": "pypotteryink/installation.html#updating",
    "href": "pypotteryink/installation.html#updating",
    "title": "Installation",
    "section": "Updating",
    "text": "Updating\nTo update PyPotteryInk to the latest version:\n\nDownload the latest version of the code\nActivate the virtual environment\nUpdate dependencies:\n\npip install -r requirements.txt --upgrade",
    "crumbs": [
      "PyPotteryInk",
      "Installation"
    ]
  },
  {
    "objectID": "pypotteryink/advanced.html",
    "href": "pypotteryink/advanced.html",
    "title": "Advanced Documentation",
    "section": "",
    "text": "version 2.0.0",
    "crumbs": [
      "PyPotteryInk",
      "Advanced Documentation"
    ]
  },
  {
    "objectID": "pypotteryink/advanced.html#introduction",
    "href": "pypotteryink/advanced.html#introduction",
    "title": "Advanced Documentation",
    "section": "Introduction",
    "text": "Introduction\n\n\n\n\n\n\nImportant\n\n\n\nWhile this guide uses the API approach, it provides a solid foundation for understanding the underlying process.\n\n\nArchaeological drawing digitisation represents a crucial step in preserving and sharing our cultural heritage. While traditionally done by hand, modern computational methods can help streamline this process while maintaining the high standards required for archaeological documentation. This guide walks you through using the ink module, a specialised tool designed for converting pencil drawings of archaeological artefacts into publication-ready inked versions.",
    "crumbs": [
      "PyPotteryInk",
      "Advanced Documentation"
    ]
  },
  {
    "objectID": "pypotteryink/advanced.html#setting-up-your-environment",
    "href": "pypotteryink/advanced.html#setting-up-your-environment",
    "title": "Advanced Documentation",
    "section": "Setting Up Your Environment",
    "text": "Setting Up Your Environment\nLet‚Äôs begin by importing the necessary functions from the toolset:\nfrom ink import process_folder, run_diagnostics\nThese two functions serve as the foundation of our processing pipeline. The run_diagnostics function helps us understand how our images will interact with the model, while process_folder handles the actual conversion process.\nThink of run_diagnostics as our planning phase and process_folder as our execution phase.",
    "crumbs": [
      "PyPotteryInk",
      "Advanced Documentation"
    ]
  },
  {
    "objectID": "pypotteryink/advanced.html#understanding-the-diagnostic-process",
    "href": "pypotteryink/advanced.html#understanding-the-diagnostic-process",
    "title": "Advanced Documentation",
    "section": "Understanding the Diagnostic Process",
    "text": "Understanding the Diagnostic Process\nBefore processing an entire collection of drawings, we need to understand how our specific drawings will interact with the model.\nFirst, let‚Äôs set up our working directory:\nmy_path = \"Montale_example\"\nNow we can run our diagnostic analysis:\nrun_diagnostics(\n    input_folder=my_path,           # Where your drawings are stored\n    model_path=\"6h-MCG.pkl\",        # The trained model file\n    num_sample_images=1,            # How many test images to analyze\n    contrast_values=[0.5, 0.75, 1, 1.5, 2, 3],  # Different contrast levels to test\n)\nLet‚Äôs understand each parameter in detail:\n\ninput_folder: This is where your pencil drawings are stored. The function will randomly select images from this folder for analysis.\nmodel_path: Points to your trained model file. This model contains the learned patterns for converting pencil drawings to inked versions.\nnum_sample_images: Controls how many images to analyse. For a small collection, 1-2 images might suffice, but for larger collections with varying drawing styles, you might want to test more.\ncontrast_values: These values help us understand how different contrast levels affect the model‚Äôs output. Think of this like adjusting the pressure of your pen when inking - too light (low contrast) might lose details, while too heavy (high contrast) might create unwanted artefacts.\n\nThe diagnostic process creates a structured output that helps us understand how our images will be processed:\ndiagnostic/\n‚îú‚îÄ‚îÄ contrast_analysis_{progressive_number}.png  # Shows how contrast affects results\n‚îú‚îÄ‚îÄ patches_{progressive_number}.png            # Shows how images will be divided\n‚îî‚îÄ‚îÄ summary_{progressive_number}.txt            # Contains detailed analysis\nLet‚Äôs examine the patch division output (Figure¬†1):\n\n\n\n\n\n\nFigure¬†1: This visualization shows how your image will be processed in smaller chunks.\n\n\n\nThe patch division is crucial because it shows us how the model will break down larger images into manageable pieces. The overlap between patches helps prevent visible seams in the final output.\nNext, let‚Äôs look at the contrast analysis (Figure¬†2):\n\n\n\n\n\n\nFigure¬†2: This analysis shows how different contrast values affect the model‚Äôs output. Notice how extreme values can either lose detail (too low) or create artefacts (too high).\n\n\n\nThis visualization is particularly important because it helps us find the sweet spot for contrast enhancement. Looking at the results:\n\nA contrast value of 0.5 is too low, causing loss of fine details\nA contrast value of 3.0 is too high, introducing unwanted artefacts\nValues between 1.0 and 1.5 seem to produce the most balanced results",
    "crumbs": [
      "PyPotteryInk",
      "Advanced Documentation"
    ]
  },
  {
    "objectID": "pypotteryink/advanced.html#processing-your-collection",
    "href": "pypotteryink/advanced.html#processing-your-collection",
    "title": "Advanced Documentation",
    "section": "Processing Your Collection",
    "text": "Processing Your Collection\nAfter understanding how our images interact with the model through diagnostics, we can proceed with processing our entire collection:\nprocess_folder(\n    input_folder=my_path,\n    model_path=\"6h-MCG.pkl\",\n    contrast_scale=1.25,            # Chosen based on diagnostic results\n    output_dir=\"Montale_processed\", # We define an output folder\n    use_fp16=True,                  # Enables faster processing\n    upscale=1                       # Upscale the image (1: no upscaling)\n)\nThe processing creates an organized output structure that helps us track and validate our results:\nMontale_processed/\n‚îú‚îÄ‚îÄ comparisons/                # Before/after comparisons\n‚îÇ   ‚îú‚îÄ‚îÄ comparison_{image_name}.jpg\n‚îú‚îÄ‚îÄ logs/                       # Detailed processing records\n‚îÇ   ‚îî‚îÄ‚îÄ processing_log_{timestamp}.txt\n‚îú‚îÄ‚îÄ {image_name}.jpg           # Final processed images\nThe log files contain valuable information about the processing:\nProcessing started at: 2024-12-30 13:26:26.607305\nConfiguration:\n- Input folder: Montale_example\n- Output directory: Montale_processed\n- Model path: model_601.pkl\n- FP16 mode: True\n- Patch size: 512px\n- Overlap: 64px\n- Contrast scale: 1.25\n- Prompt: make it ready for publication\n\n[Processing details...]\nThe comparison images (Figure¬†3) help us verify the quality of our results:\n\n\n\n\n\n\nFigure¬†3: Side-by-side comparison showing the transformation from pencil drawing to inked version.",
    "crumbs": [
      "PyPotteryInk",
      "Advanced Documentation"
    ]
  },
  {
    "objectID": "pypotteryink/advanced.html#best-practices-and-troubleshooting",
    "href": "pypotteryink/advanced.html#best-practices-and-troubleshooting",
    "title": "Advanced Documentation",
    "section": "Best Practices and Troubleshooting",
    "text": "Best Practices and Troubleshooting\nTo get the best results from your processing:\n\nAlways start with diagnostics, even if you‚Äôre familiar with the model. Different collections might require slightly different parameters.\nPay attention to image resolution. The model works best with clear, well-scanned drawings. If your scans are too light or too dark, consider adjusting them before processing (Section¬†3).\nMonitor the processing logs. If you see many failed conversions, it might indicate issues with your input images or parameters.\nReview the comparison images carefully. They can help you spot any systematic issues that might need addressing.\nUpscaling can help achieve a better result, especially when dealing with complex decorations. Upscaling factor is just for processing. The upscaling factor is for processing only. It doesn‚Äôt affect the output size.\n\n\n\n\n\n\n\nImportant\n\n\n\nRemember that while this tool automates much of the inking process, it‚Äôs still important to review the results with an archaeological perspective. The model is a tool to assist, not replace, archaeological expertise.",
    "crumbs": [
      "PyPotteryInk",
      "Advanced Documentation"
    ]
  },
  {
    "objectID": "pypotteryink/advanced.html#introduction-1",
    "href": "pypotteryink/advanced.html#introduction-1",
    "title": "Advanced Documentation",
    "section": "Introduction",
    "text": "Introduction\nAfter generating inked versions of archaeological drawings, we often need to refine the results to meet some publication requirements or enhance the result. The post-processing module provides tools for image binarization, background removal, and stippling pattern enhancement. This guide will walk you through the main functions and best practices for using these tools.",
    "crumbs": [
      "PyPotteryInk",
      "Advanced Documentation"
    ]
  },
  {
    "objectID": "pypotteryink/advanced.html#required-libraries",
    "href": "pypotteryink/advanced.html#required-libraries",
    "title": "Advanced Documentation",
    "section": "Required Libraries",
    "text": "Required Libraries\nLet‚Äôs start by importing the necessary functions:\nfrom postprocessing import (\n    binarize_image,\n    remove_white_background,\n    process_image_binarize,\n    binarize_folder_images,\n    enhance_stippling,\n    modify_stippling,\n    control_stippling\n)",
    "crumbs": [
      "PyPotteryInk",
      "Advanced Documentation"
    ]
  },
  {
    "objectID": "pypotteryink/advanced.html#binarization-and-background-removal",
    "href": "pypotteryink/advanced.html#binarization-and-background-removal",
    "title": "Advanced Documentation",
    "section": "Binarization and Background Removal",
    "text": "Binarization and Background Removal\nFor many publication contexts, we want to remove the white background to create binary transparent images that can be easily integrated into figures:\n\n# You can combine binarization and background removal in one step:\nprocessed_image = process_image_binarize(\n    image_path=\"path/to/image.jpg\",\n    binarize_threshold=127,\n    white_threshold=250,\n    save_path=\"output.png\"  # Must use PNG to preserve transparency\n)\nHere the result:\n\n\n\nOriginal ink\n\n\n\n\n\nBinarized and background-clear image",
    "crumbs": [
      "PyPotteryInk",
      "Advanced Documentation"
    ]
  },
  {
    "objectID": "pypotteryink/advanced.html#batch-processing",
    "href": "pypotteryink/advanced.html#batch-processing",
    "title": "Advanced Documentation",
    "section": "Batch Processing",
    "text": "Batch Processing\nWhen working with multiple drawings, you can process an entire folder at once:\nbinarize_folder_images(\n    input_folder=\"path/to/drawings\",\n    binarize_threshold=127,\n    white_threshold=250\n)\nThis creates a new folder with ‚Äú_binarized‚Äù suffix containing processed images",
    "crumbs": [
      "PyPotteryInk",
      "Advanced Documentation"
    ]
  },
  {
    "objectID": "pypotteryink/advanced.html#advanced-stippling-control",
    "href": "pypotteryink/advanced.html#advanced-stippling-control",
    "title": "Advanced Documentation",
    "section": "Advanced Stippling Control",
    "text": "Advanced Stippling Control\nBy using the post-processing module you can enhance and modify stippling patterns, check out this example!\n\nEnhancing Stippling Patterns\nFirst, we can isolate and enhance existing stippling patterns:\n# Separate the main drawing from stippling patterns\nprocessed_img, stippling_pattern = enhance_stippling(\n    img=Image.open(\"drawing.png\"),\n    min_size=80,     # Minimum size of dots to preserve\n    connectivity=2    # How dots connect to form patterns\n)\nThe function returns two images:\n\nprocessed_img: Main drawing without small dots\nstippling_pattern: Isolated stippling pattern\n\n\n\n\nImage without dotting\n\n\n\n\n\nIsolated dotting\n\n\n\n\nModifying Stippling\nOnce we‚Äôve isolated the stippling patterns, we can modify them in several ways:\nmodified_image = modify_stippling(\n    processed_img=processed_img,\n    stippling_pattern=stippling_pattern,\n    operation='dilate',  # Options: 'dilate', 'fade', or 'both'\n    intensity=0.5,      # Controls strength of dilation (0.0-1.0)\n    opacity=1.0         # Controls darkness of stippling (0.0-1.0)\n)\nThe operation parameter offers three different modification approaches:\n\n‚Äòdilate‚Äô: Makes dots larger while maintaining their density\n‚Äòfade‚Äô: Adjusts the opacity of dots without changing their size\n‚Äòboth‚Äô: Combines dilation and opacity adjustments\n\nHere a bunch of examples:\nFirst, we increase the dots using the ‚Äúdilate‚Äù option:\n\nSecondly, we try to adjust the opacity using the fade option:\n\nFinally, we combine the techniques:\n\n\n\nBatch Stippling Control\nFor consistent stippling across multiple drawings:\ncontrol_stippling(\n    input_folder=\"path/to/drawings\",\n    min_size=50,          # Size threshold for dot detection\n    connectivity=2,        # How dots connect to each other\n    operation='fade',      # Type of modification\n    intensity=0.5,        # Strength of effect\n    opacity=0.5           # Final opacity of stippling\n)\nThis creates a new folder with ‚Äú_dotting_modified‚Äù suffix containing the processed images.",
    "crumbs": [
      "PyPotteryInk",
      "Advanced Documentation"
    ]
  },
  {
    "objectID": "pypotteryink/advanced.html#understanding-the-parameters",
    "href": "pypotteryink/advanced.html#understanding-the-parameters",
    "title": "Advanced Documentation",
    "section": "Understanding the Parameters",
    "text": "Understanding the Parameters\nWhen working with the stippling controls, it‚Äôs important to understand how different parameters affect the result:\n\nmin_size: Controls which dots are considered part of stippling patterns versus actual drawing elements. Larger values preserve only larger dots.\nconnectivity: Determines how dots are grouped together. Higher values (2 or 3) allow more diagonal connections.\nintensity: When dilating, controls how much dots expand. Values between 0.3-0.7 usually give the best results.\nopacity: Controls the final darkness of stippling patterns. Lower values create lighter shading.",
    "crumbs": [
      "PyPotteryInk",
      "Advanced Documentation"
    ]
  },
  {
    "objectID": "pypotteryink/advanced.html#best-practices",
    "href": "pypotteryink/advanced.html#best-practices",
    "title": "Advanced Documentation",
    "section": "Best Practices",
    "text": "Best Practices\n\nAlways work with high-resolution images to ensure clean binarization.\nStart with conservative threshold values and adjust as needed.\nSave intermediate results when working with stippling modifications.\nTest your parameters on a small sample before processing entire collections.",
    "crumbs": [
      "PyPotteryInk",
      "Advanced Documentation"
    ]
  },
  {
    "objectID": "pypotteryink/advanced.html#introduction-to-image-preprocessing",
    "href": "pypotteryink/advanced.html#introduction-to-image-preprocessing",
    "title": "Advanced Documentation",
    "section": "Introduction to Image Preprocessing",
    "text": "Introduction to Image Preprocessing\nArchaeological drawings often vary in their characteristics due to different artists, scanning conditions, and original materials. These variations can impact the performance of the model. This guide outlines the preprocessing pipeline that helps standardise images before they are processed by the model.",
    "crumbs": [
      "PyPotteryInk",
      "Advanced Documentation"
    ]
  },
  {
    "objectID": "pypotteryink/advanced.html#import-required-libraries",
    "href": "pypotteryink/advanced.html#import-required-libraries",
    "title": "Advanced Documentation",
    "section": "Import Required Libraries",
    "text": "Import Required Libraries\nfrom ink import process_folder, process_single_image\nfrom preprocessing import DatasetAnalyzer, process_image_metrics, \n                visualize_metrics_change, process_folder_metrics",
    "crumbs": [
      "PyPotteryInk",
      "Advanced Documentation"
    ]
  },
  {
    "objectID": "pypotteryink/advanced.html#understanding-the-problem-image-metric-variations",
    "href": "pypotteryink/advanced.html#understanding-the-problem-image-metric-variations",
    "title": "Advanced Documentation",
    "section": "Understanding the Problem: Image Metric Variations",
    "text": "Understanding the Problem: Image Metric Variations\nLet‚Äôs examine a specific case that illustrates why preprocessing is necessary. Consider the following high-contrast image (Figure¬†4).\n\n\n\n\n\n\nFigure¬†4: An archaeological drawing with excessive contrast. The high contrast is evident in the black areas\n\n\n\nWhen we apply our model directly to this image without preprocessing, we get problematic results (Figure¬†5):\n\n\n\n\n\n\nFigure¬†5: Direct model application showing artefacts. Note the missing dotting patterns and blue tiling artefacts in the bottom-right region.\n\n\n\nThe output shows two significant issues:\n\nMissing dot patterns in shaded areas\nUnwanted blue tiling artefacts, particularly visible in the bottom-right section\n\nThese issues arise because the input image‚Äôs characteristics deviate significantly from the training dataset‚Äôs standard properties. Our preprocessing pipeline addresses this by analysing and adjusting key image metrics to align them with our training data distribution.",
    "crumbs": [
      "PyPotteryInk",
      "Advanced Documentation"
    ]
  },
  {
    "objectID": "pypotteryink/advanced.html#image-metrics-analysis",
    "href": "pypotteryink/advanced.html#image-metrics-analysis",
    "title": "Advanced Documentation",
    "section": "Image Metrics Analysis",
    "text": "Image Metrics Analysis\nThe DatasetAnalyzer class calculates eight key metrics that characterise archaeological drawings:\n\nMean brightness: Overall lightness of the image\nStandard deviation: Measure of tonal variation\nContrast ratio: Ratio between the brightest and darkest areas\nMedian: Middle intensity value\nDynamic range: Difference between the 99th and 1st percentile intensities\nEntropy: Measure of information content\nIQR (Interquartile Range): Spread of middle 50% of intensity values\nNon-empty ratio: Proportion of pixels above background threshold\n\nYou can either analyse your own dataset to establish reference metrics or use our pre-computed metrics from the training dataset:\n# Option 1: Analyse your own dataset\nanalyzer = DatasetAnalyzer()\nmodel_stats = analyzer.analyze_dataset('PATH_TO_YOUR_DATASET')\nanalyzer.save_analysis('DATASET_RESULTS_PATH')\n\n# Option 2: Use pre-computed metrics\nanalyzer = DatasetAnalyzer()\nanalyzer = analyzer.load_analysis('Montale_stats.npy')\nmodel_stats = analyzer.distributions\nThe distribution of these metrics can be visualized:\nanalyzer.visualize_distributions_kde()\n\n\n\n\n\n\nFigure¬†6: Figure 6: Distribution of image metrics from the training dataset. Each plot shows the distribution curve, actual data points, mean (red dashed line), median (blue dotted line), and ¬±2œÉ range (green shading).",
    "crumbs": [
      "PyPotteryInk",
      "Advanced Documentation"
    ]
  },
  {
    "objectID": "pypotteryink/advanced.html#preprocessing-pipeline",
    "href": "pypotteryink/advanced.html#preprocessing-pipeline",
    "title": "Advanced Documentation",
    "section": "Preprocessing Pipeline",
    "text": "Preprocessing Pipeline\nThe preprocessing pipeline adjusts images to match the statistical properties of the training dataset. Here‚Äôs how to process a single image:\noriginal_image = 'PATH_TO_YOUR_IMAGE'\nadjusted_image, adjusted_metrics = process_image_metrics(original_image, model_stats)\nThe pipeline performs these adjustments:\n\nContrast normalization based on the training set‚Äôs contrast ratio distribution\nDynamic range adjustment to match the target range\nBrightness correction to align with the training set‚Äôs mean intensity\n\nThe adjusted image shows more balanced contrast and better preservation of details:\n\n\n\n\n\n\nFigure¬†7: Figure 7: Preprocessed image showing normalized contrast and preserved details.\n\n\n\nWe can visualize how the preprocessing affected our image metrics:\n\n\n\n\n\n\nFigure¬†8: Figure 8: Comparison of original (orange) and adjusted (teal) metrics against the training distribution.",
    "crumbs": [
      "PyPotteryInk",
      "Advanced Documentation"
    ]
  },
  {
    "objectID": "pypotteryink/advanced.html#model-application",
    "href": "pypotteryink/advanced.html#model-application",
    "title": "Advanced Documentation",
    "section": "Model Application",
    "text": "Model Application\nAfter preprocessing, the model produces significantly better results:\n\n\n\n\n\n\nFigure¬†9: Figure 9: Model output after preprocessing, showing proper dotting patterns and no artifacts.\n\n\n\nThe improvements include:\n\nConsistent dotting patterns in shaded areas\nNo colour artefacts or tiling effects\nBetter preservation of fine details\nMore natural transition between different tonal areas\n\nI‚Äôll add a section about batch processing to the documentation:",
    "crumbs": [
      "PyPotteryInk",
      "Advanced Documentation"
    ]
  },
  {
    "objectID": "pypotteryink/advanced.html#batch-processing-1",
    "href": "pypotteryink/advanced.html#batch-processing-1",
    "title": "Advanced Documentation",
    "section": "Batch Processing",
    "text": "Batch Processing\nWhile processing individual images is useful for testing and fine-tuning parameters, in archaeological practice we often need to process entire collections of drawings. The process_folder_metrics function automates this task by applying our preprocessing pipeline to all images in a directory.\nHere‚Äôs how to use batch processing:\n# Define the input folder containing your drawings\ninput_folder = \"path/to/your/drawings\"\n\n# Process all images in the folder\nprocess_folder_metrics(\n    input_folder=input_folder,\n    model_stats=model_stats,\n    file_extensions=('.jpg', '.jpeg', '.png')  # Supported file formats\n)\nThe function creates a new directory named input_folder_adjusted that contains all the processed images. During processing, it provides detailed feedback about each image:\nüìÅ Found 25 images to process\n==================================================\n\nüîç Analyzing: drawing_001.jpg\n‚öôÔ∏è Image Analysis:\n‚îî‚îÄ Contrast: 0.85x | Brightness adjustment needed\n‚ú® Adjustments applied\n\nProgress: 1/25\n--------------------------------------------------\n\nüîç Analyzing: drawing_002.jpg\n‚úÖ Image metrics within normal ranges\n\nProgress: 2/25\n--------------------------------------------------\nAt the end of processing, you‚Äôll receive a summary report:\nüìä Processing Summary\n==================================================\nTotal processed:  25\nImages adjusted:  18\nNo adjustments:   7\n\nüíæ All images saved to: path/to/your/drawings_adjusted\nThis summary helps you understand how many images required adjustment, which can be useful for:\n\nIdentifying systematic issues in your drawing or scanning process\nPlanning future preprocessing strategies\nDocumenting the processing pipeline for publication\n\nThe batch processing maintains all the benefits of individual processing while saving time and ensuring consistency across your entire dataset. All adjusted images will have metrics that align with your training data distribution, leading to better results when applying the model.\nNote that each image still receives individual analysis and custom adjustments - the batch process doesn‚Äôt apply a one-size-fits-all transformation. Instead, it analyses each drawing‚Äôs specific characteristics and applies the precise adjustments needed to bring that particular image into alignment with your target metrics.",
    "crumbs": [
      "PyPotteryInk",
      "Advanced Documentation"
    ]
  },
  {
    "objectID": "pypotteryink/advanced.html#prerequisites",
    "href": "pypotteryink/advanced.html#prerequisites",
    "title": "Advanced Documentation",
    "section": "Prerequisites",
    "text": "Prerequisites\nBefore starting the fine-tuning process, ensure you have:\n\nA GPU with at least 20GB VRAM for training\nPython 3.10 or higher\nA paired dataset of pencil drawings and their inked versions\nStorage space for model checkpoints and training data",
    "crumbs": [
      "PyPotteryInk",
      "Advanced Documentation"
    ]
  },
  {
    "objectID": "pypotteryink/advanced.html#environment-setup",
    "href": "pypotteryink/advanced.html#environment-setup",
    "title": "Advanced Documentation",
    "section": "Environment Setup",
    "text": "Environment Setup\n\nFirst, clone the repository:\ngit clone https://github.com/GaParmar/img2img-turbo.git\nInstall the required dependencies:\npip install -r img2img-turbo/requirements.txt\npip install git+https://github.com/openai/CLIP.git\npip install wandb vision_aided_loss huggingface-hub==0.25.0",
    "crumbs": [
      "PyPotteryInk",
      "Advanced Documentation"
    ]
  },
  {
    "objectID": "pypotteryink/advanced.html#dataset-preparation",
    "href": "pypotteryink/advanced.html#dataset-preparation",
    "title": "Advanced Documentation",
    "section": "Dataset Preparation",
    "text": "Dataset Preparation\n\nTo create a training dataset check out the original docs\nImportant considerations for dataset preparation:\n\nImages should be paired (same filename in both folders)\nStandard image formats (jpg, jpeg, png) are supported\nBoth pencil and inked versions should be aligned\nRecommended resolution: at least 512x512 pixels\n\nData requirements:\n\nMinimum recommended: 10-20 pairs for fine-tuning\nEach drawing should be clean and well-scanned\nInclude variety in pottery types and decorations\nConsistent drawing style across the dataset",
    "crumbs": [
      "PyPotteryInk",
      "Advanced Documentation"
    ]
  },
  {
    "objectID": "pypotteryink/advanced.html#setting-up-fine-tuning",
    "href": "pypotteryink/advanced.html#setting-up-fine-tuning",
    "title": "Advanced Documentation",
    "section": "Setting Up Fine-tuning",
    "text": "Setting Up Fine-tuning\nTo fine-tune a pre-trained model (like ‚Äú6h-MCG‚Äù), you‚Äôll need to modify the base img2img-turbo repository. This enables the use of a pre-trained model as a starting point for your specialised training.\n\nPrepare the Repository:\n\nNavigate to your cloned img2img-turbo directory\n\ncd img2img-turbo\nReplace Key Files:\n\nCopy these files from the PyPotteryInk repository‚Äôs ‚Äúfine-tuning‚Äù folder into the src folder:\n\npix2pix_turbo.py\ntrain_pix2pix_turbo.py\n\n\nThese modified files contain the necessary adaptations to support training from a pre-trained model.",
    "crumbs": [
      "PyPotteryInk",
      "Advanced Documentation"
    ]
  },
  {
    "objectID": "pypotteryink/advanced.html#running-fine-tuning",
    "href": "pypotteryink/advanced.html#running-fine-tuning",
    "title": "Advanced Documentation",
    "section": "Running Fine-tuning",
    "text": "Running Fine-tuning\n\nInitialize Accelerate Environment:\naccelerate config\nThis will guide you through setting up your training environment. Follow the prompts to configure for your GPU setup.\nStart Training:\naccelerate launch src/train_pix2pix_turbo.py \\\n    --pretrained_model_name_or_path=\"6h-MCG.pkl\" \\\n    --output_dir=\"YOUR_OUTPUT_DIR\" \\\n    --dataset_folder=\"YOUR_INPUT_DATA\" \\\n    --resolution=512 \\\n    --train_batch_size=2 \\\n    --enable_xformers_memory_efficient_attention \\\n    --viz_freq 25 \\\n    --track_val_fid \\\n    --report_to \"wandb\" \\\n    --tracker_project_name \"YOUR_PROJECT_NAME\"\nKey Parameters:\n\npretrained_model_name_or_path: Path to your pre-trained model (e.g., ‚Äú6h-MCG.pkl‚Äù)\noutput_dir: Where to save training outputs and checkpoints\ndataset_folder: Location of your training dataset\nresolution: Image resolution (512 recommended)\ntrain_batch_size: Number of images per training batch\nviz_freq: How often to generate visualization samples\ntrack_val_fid: Enable FID score tracking\ntracker_project_name: Your Weights & Biases project name\n\n\nNote: Adjust the batch size based on your GPU memory. Start with 2 and increase if your GPU can handle it.",
    "crumbs": [
      "PyPotteryInk",
      "Advanced Documentation"
    ]
  },
  {
    "objectID": "pypotteryink/advanced.html#important-considerations",
    "href": "pypotteryink/advanced.html#important-considerations",
    "title": "Advanced Documentation",
    "section": "Important Considerations",
    "text": "Important Considerations\n\nEnsure your pre-trained model file (e.g., ‚Äú6h-MCG.pkl‚Äù) is in the correct location\nMonitor GPU memory usage during training\nUse Weights & Biases (wandb) to track training progress\nCheck the output directory periodically for sample outputs\nTraining time will vary based on your GPU and dataset size",
    "crumbs": [
      "PyPotteryInk",
      "Advanced Documentation"
    ]
  },
  {
    "objectID": "pypotteryink/api.html",
    "href": "pypotteryink/api.html",
    "title": "API Documentation",
    "section": "",
    "text": "version 2.0.0",
    "crumbs": [
      "PyPotteryInk",
      "API Documentation"
    ]
  },
  {
    "objectID": "pypotteryink/api.html#overview",
    "href": "pypotteryink/api.html#overview",
    "title": "API Documentation",
    "section": "Overview",
    "text": "Overview\nThe ink module provides the foundation for transforming archaeological pencil drawings into publication-ready inked versions. Each function serves a specific purpose in the workflow, carefully preserving archaeological details while ensuring professional output quality.",
    "crumbs": [
      "PyPotteryInk",
      "API Documentation"
    ]
  },
  {
    "objectID": "pypotteryink/api.html#process-single-image",
    "href": "pypotteryink/api.html#process-single-image",
    "title": "API Documentation",
    "section": "Process Single Image",
    "text": "Process Single Image\ndef process_single_image(\n    input_image_path_or_pil: Union[str, Image.Image],\n    prompt: str,\n    model_path: str,\n    output_dir: str = 'output',\n    use_fp16: bool = False,\n    output_name: Optional[str] = None,\n    contrast_scale: float = 1,\n    return_pil: bool = False,\n    patch_size: int = 512,\n    overlap: int = 64,\n    upscale: float = 1,\n) -&gt; Union[str, Image.Image]\nThis function handles the conversion of individual drawings, providing fine control over the processing parameters. Think of it as a digital artisan, carefully converting each drawing while maintaining archaeological accuracy.\n\nCore Parameters\n\ninput_image_path_or_pil\n\nYour drawing to process - either a file path or a PIL Image\n\nprompt\n\nInstructions for the model, typically ‚Äúmake it ready for publication‚Äù\n\nmodel_path\n\nLocation of your trained model file\n\n\n\n\nOptional Controls\n\ncontrast_scale ¬∑ default: 1.0\n\nFine-tunes the intensity of lines and shading. Values between 1.25-1.5 often work best for archaeological materials.\n\npatch_size ¬∑ default: 512\n\nProcessing segment size. Like dividing a large drawing into manageable sections.\n\noverlap ¬∑ default: 64\n\nControls smooth transitions between processed sections.\n\nupscale ¬∑ default: 1\n\nUpscaling or downscaling factor for processing. It doesn‚Äôt affect the output size\n\n\n\n\nExamples\nBasic processing:\nresult = process_single_image(\n    \"vessel_123.jpg\",\n    prompt=\"make it ready for publication\",\n    model_path=\"model_601.pkl\"\n)",
    "crumbs": [
      "PyPotteryInk",
      "API Documentation"
    ]
  },
  {
    "objectID": "pypotteryink/api.html#process-folder",
    "href": "pypotteryink/api.html#process-folder",
    "title": "API Documentation",
    "section": "Process Folder",
    "text": "Process Folder\ndef process_folder(\n    input_folder: str,\n    model_path: str,\n    prompt: str = \"make it ready for publication\",\n    output_dir: str = 'output',\n    use_fp16: bool = False,\n    contrast_scale: float = 1,\n    patch_size: int = 512,\n    overlap: int = 64,\n    file_extensions: tuple = ('.jpg', '.jpeg', '.png'),\n    upscale: float = 1,\n) -&gt; dict\nBatch processes a directory of archaeological drawings, maintaining consistency across the entire collection. The function tracks progress and generates detailed logs and comparisons.\n\nCore Parameters\n\ninput_folder\n\nDirectory containing your archaeological drawings\n\nmodel_path\n\nLocation of your trained model file\n\n\n\n\nOptional Controls\n\ncontrast_scale ¬∑ default: 1.0\n\nGlobal contrast adjustment for the entire batch\n\nfile_extensions ¬∑ default: (‚Äò.jpg‚Äô, ‚Äò.jpeg‚Äô, ‚Äò.png‚Äô)\n\nSupported file types to process\n\nupscale ¬∑ default: 1\n\nUpscaling or downscaling factor for processing. It doesn‚Äôt affect the output size\n\n\n\n\nReturns\nReturns a dictionary containing: - successful: Number of successfully processed images - failed: Number of failed conversions - failed_files: List of problematic files - average_time: Mean processing time per image - log_file: Path to detailed processing log - comparison_dir: Path to before/after comparisons\n\n\nExamples\nProcess all drawings in a directory:\nresults = process_folder(\n    \"excavation_2024_drawings/\",\n    model_path=\"model_601.pkl\",\n    contrast_scale=1.25\n)",
    "crumbs": [
      "PyPotteryInk",
      "API Documentation"
    ]
  },
  {
    "objectID": "pypotteryink/api.html#run-diagnostics",
    "href": "pypotteryink/api.html#run-diagnostics",
    "title": "API Documentation",
    "section": "Run Diagnostics",
    "text": "Run Diagnostics\ndef run_diagnostics(\n    input_folder: str,\n    model_path: str,\n    prompt: str = \"make it ready for publication\",\n    patch_size: int = 512,\n    overlap: int = 64,\n    num_sample_images: int = 5,\n    contrast_values: list = [0.5, 0.75, 1, 1.5, 2, 3],\n    output_dir: str = 'diagnostics'\n) -&gt; None\nPerforms preliminary analysis on your dataset to optimize processing parameters. Creates visualizations of patch divisions and contrast effects to help fine-tune settings.\n\nCore Parameters\n\ninput_folder\n\nDirectory with sample drawings to analyse\n\nmodel_path\n\nLocation of your trained model file\n\n\n\n\nOptional Parameters\n\nnum_sample_images ¬∑ default: 5\n\nNumber of drawings to analyse (max 5)\n\ncontrast_values ¬∑ default: [0.5, 0.75, 1, 1.5, 2, 3]\n\nContrast levels to test\n\n\n\n\nGenerated Outputs\n\nPatch visualization diagrams\nContrast effect comparisons\nImage summary statistics\nProcessing recommendations\n\n\n\nExamples\nRun analysis on a new dataset:\nrun_diagnostics(\n    \"new_site_drawings/\",\n    model_path=\"model_601.pkl\",\n    contrast_values=[0.75, 1, 1.25, 1.5]\n)",
    "crumbs": [
      "PyPotteryInk",
      "API Documentation"
    ]
  },
  {
    "objectID": "pypotteryink/api.html#calculate-patches",
    "href": "pypotteryink/api.html#calculate-patches",
    "title": "API Documentation",
    "section": "Calculate Patches",
    "text": "Calculate Patches\ndef calculate_patches(\n    width: int,\n    height: int,\n    patch_size: int = 512,\n    overlap: int = 64\n) -&gt; tuple[int, int, int]\nInternal utility that determines optimal patch division for processing large drawings. Ensures efficient memory usage while maintaining detail preservation.\n\nParameters\n\nwidth, height\n\nImage dimensions in pixels\n\npatch_size ¬∑ default: 512\n\nSize of processing segments\n\noverlap ¬∑ default: 64\n\nOverlap between segments\n\n\n\n\nReturns\nReturns a tuple containing: - total_patches: Total number of segments - patches_per_row: Number of patches horizontally - num_rows: Number of patches vertically\n\n\nExamples\nCalculate processing segments:\npatches, rows, cols = calculate_patches(2048, 1536)\nprint(f\"Processing in {patches} segments\")",
    "crumbs": [
      "PyPotteryInk",
      "API Documentation"
    ]
  },
  {
    "objectID": "pypotteryink/api.html#overview-1",
    "href": "pypotteryink/api.html#overview-1",
    "title": "API Documentation",
    "section": "Overview",
    "text": "Overview\nThe postprocessing module provides tools for refining and enhancing the converted archaeological drawings, focusing on output quality and archaeological detail preservation.",
    "crumbs": [
      "PyPotteryInk",
      "API Documentation"
    ]
  },
  {
    "objectID": "pypotteryink/api.html#binarize-image",
    "href": "pypotteryink/api.html#binarize-image",
    "title": "API Documentation",
    "section": "Binarize Image",
    "text": "Binarize Image\ndef binarize_image(\n    image: Union[PIL.Image, np.ndarray],\n    threshold: int = 127\n) -&gt; PIL.Image\nConverts grayscale drawings to binary format, ideal for final publication preparation.\n\nParameters\n\nimage\n\nInput image (PIL Image or numpy array)\n\nthreshold\n\nIntensity threshold (0-255)\n\n\n\n\nExamples\nbinary = binarize_image(\"processed_vessel.png\", threshold=150)",
    "crumbs": [
      "PyPotteryInk",
      "API Documentation"
    ]
  },
  {
    "objectID": "pypotteryink/api.html#remove-white-background",
    "href": "pypotteryink/api.html#remove-white-background",
    "title": "API Documentation",
    "section": "Remove White Background",
    "text": "Remove White Background\ndef remove_white_background(\n    image: PIL.Image,\n    threshold: int = 250\n) -&gt; PIL.Image\nCreates transparent backgrounds for archaeological drawings, useful for figure composition.\n\nParameters\n\nimage\n\nInput drawing\n\nthreshold\n\nValue above which pixels are considered white\n\n\n\n\nExamples\ntransparent = remove_white_background(\"vessel.png\", threshold=245)",
    "crumbs": [
      "PyPotteryInk",
      "API Documentation"
    ]
  },
  {
    "objectID": "pypotteryink/api.html#process-image-binarize",
    "href": "pypotteryink/api.html#process-image-binarize",
    "title": "API Documentation",
    "section": "Process Image Binarize",
    "text": "Process Image Binarize\ndef process_image_binarize(\n    image_path: str,\n    binarize_threshold: int = 127,\n    white_threshold: int = 250,\n    save_path: Optional[str] = None\n) -&gt; PIL.Image\nCombined function for binarization and background removal.\n\nParameters\n\nimage_path\n\nPath to input image\n\nbinarize_threshold\n\nThreshold for black/white conversion\n\nwhite_threshold\n\nThreshold for transparency\n\nsave_path\n\nOptional output path",
    "crumbs": [
      "PyPotteryInk",
      "API Documentation"
    ]
  },
  {
    "objectID": "pypotteryink/api.html#binarize-folder-images",
    "href": "pypotteryink/api.html#binarize-folder-images",
    "title": "API Documentation",
    "section": "Binarize Folder Images",
    "text": "Binarize Folder Images\ndef binarize_folder_images(\n    input_folder: str,\n    binarize_threshold: int = 127,\n    white_threshold: int = 250\n) -&gt; None\nBatch processes a folder of drawings, applying binarization and background removal.\n\nParameters\n\ninput_folder\n\nDirectory containing drawings\n\nbinarize_threshold\n\nThreshold for binarization\n\nwhite_threshold\n\nThreshold for transparency",
    "crumbs": [
      "PyPotteryInk",
      "API Documentation"
    ]
  },
  {
    "objectID": "pypotteryink/api.html#enhance-stippling",
    "href": "pypotteryink/api.html#enhance-stippling",
    "title": "API Documentation",
    "section": "Enhance Stippling",
    "text": "Enhance Stippling\ndef enhance_stippling(\n    img: PIL.Image,\n    min_size: int = 80,\n    connectivity: int = 2\n) -&gt; Tuple[PIL.Image, PIL.Image]\nIsolates and enhances stippling patterns in archaeological drawings.\n\nParameters\n\nimg\n\nInput drawing\n\nmin_size\n\nMinimum object size to preserve\n\nconnectivity\n\nConnection parameter for pattern detection\n\n\n\n\nReturns\nReturns tuple containing: - processed_image: Drawing with enhanced stippling - stippling_pattern: Isolated stippling mask",
    "crumbs": [
      "PyPotteryInk",
      "API Documentation"
    ]
  },
  {
    "objectID": "pypotteryink/api.html#modify-stippling",
    "href": "pypotteryink/api.html#modify-stippling",
    "title": "API Documentation",
    "section": "Modify Stippling",
    "text": "Modify Stippling\ndef modify_stippling(\n    processed_img: PIL.Image,\n    stippling_pattern: PIL.Image,\n    operation: str = 'dilate',\n    intensity: float = 0.5,\n    opacity: float = 1.0\n) -&gt; PIL.Image\nAdjusts stippling patterns through morphological operations and intensity modulation.\n\nParameters\n\nprocessed_img\n\nBase image without stippling\n\nstippling_pattern\n\nIsolated stippling pattern\n\noperation\n\nType of modification (‚Äòdilate‚Äô, ‚Äòfade‚Äô, or ‚Äòboth‚Äô)\n\nintensity\n\nMorphological modification strength (0.0-1.0)\n\nopacity\n\nStippling opacity factor (0.0-1.0)\n\n\n\n\nExamples\nenhanced = modify_stippling(\n    base_img,\n    dots_pattern,\n    operation='both',\n    intensity=0.7,\n    opacity=0.8\n)",
    "crumbs": [
      "PyPotteryInk",
      "API Documentation"
    ]
  },
  {
    "objectID": "pypotteryink/api.html#control-stippling",
    "href": "pypotteryink/api.html#control-stippling",
    "title": "API Documentation",
    "section": "Control Stippling",
    "text": "Control Stippling\ndef control_stippling(\n    input_folder: str,\n    min_size: int = 50,\n    connectivity: int = 2,\n    operation: str = 'fade',\n    intensity: float = 0.5,\n    opacity: float = 0.5\n) -&gt; None\nBatch processes stippling patterns in a folder of archaeological drawings.\n\nParameters\n\ninput_folder\n\nDirectory containing drawings\n\nmin_size\n\nMinimum object size to preserve\n\nconnectivity\n\nPattern detection parameter\n\noperation\n\nModification type (‚Äòdilate‚Äô, ‚Äòfade‚Äô, ‚Äòboth‚Äô)\n\nintensity\n\nModification strength\n\nopacity\n\nPattern opacity\n\n\n\n\nExamples\ncontrol_stippling(\n    \"vessel_drawings/\",\n    min_size=60,\n    operation='both',\n    intensity=0.6\n)",
    "crumbs": [
      "PyPotteryInk",
      "API Documentation"
    ]
  },
  {
    "objectID": "pypotteryink/api.html#overview-2",
    "href": "pypotteryink/api.html#overview-2",
    "title": "API Documentation",
    "section": "Overview",
    "text": "Overview\nThe preprocessing module provides tools for analyzing and adjusting archaeological drawings before conversion. It ensures optimal input quality through statistical analysis and targeted adjustments.",
    "crumbs": [
      "PyPotteryInk",
      "API Documentation"
    ]
  },
  {
    "objectID": "pypotteryink/api.html#dataset-analyzer",
    "href": "pypotteryink/api.html#dataset-analyzer",
    "title": "API Documentation",
    "section": "Dataset Analyzer",
    "text": "Dataset Analyzer\nclass DatasetAnalyzer:\n    def __init__(self):\n        self.metrics = {}\n        self.distributions = {}\nA comprehensive tool for analysing collections of archaeological drawings, establishing statistical baselines for quality control.\n\nKey Methods\n\nanalyze_image\ndef analyze_image(self, image: Union[str, Image.Image]) -&gt; dict\nExtracts key metrics from a single drawing.\nReturns\n\nmean: Average brightness\nstd: Standard deviation\ncontrast_ratio: Dynamic range measure\nmedian: Middle intensity value\ndynamic_range: Total intensity range\nentropy: Image information content\niqr: Inter-quartile range\nnon_empty_ratio: Drawing density measure\n\n\n\nanalyze_dataset\ndef analyze_dataset(\n    self, \n    dataset_path: str,\n    file_pattern: tuple = ('.png', '.jpg', '.jpeg')\n) -&gt; dict\nBuilds statistical distributions from a collection of drawings.\n\n\nvisualize_distributions_kde\ndef visualize_distributions_kde(\n    self,\n    metrics_to_plot: Optional[List[str]] = None,\n    save: bool = False\n)\nCreates KDE plots of metric distributions with statistical annotations.\n\n\nsave_analysis\ndef save_analysis(self, path: str) -&gt; None\nSaves the current analysis results to a file for later use. This is particularly useful when establishing reference metrics for a specific archaeological context or drawing style.\n\nParameters\n\npath\n\nFile path to save the analysis results\n\n\n\n\nExamples\nanalyzer = DatasetAnalyzer()\nstats = analyzer.analyze_dataset(\"reference_drawings/\")\nanalyzer.save_analysis(\"reference_metrics.npy\")\n\n\n\nload_analysis\n@classmethod\ndef load_analysis(cls, path: str) -&gt; 'DatasetAnalyzer'\nClass method that loads previously saved analysis results. This allows reuse of established reference metrics without reanalyzing the dataset.\n\nParameters\n\npath\n\nPath to previously saved analysis file\n\n\n\n\nReturns\nReturns a new DatasetAnalyzer instance with loaded analysis results\n\n\nExamples\n# Load previously computed statistics\nanalyzer = DatasetAnalyzer.load_analysis(\"reference_metrics.npy\")\n\n# Use loaded stats for quality checks\ncheck = check_image_quality(\"new_drawing.jpg\", analyzer.distributions)\nThese methods enable efficient reuse of analysis results across multiple processing sessions, particularly valuable when working with established archaeological documentation standards or specific site collections.",
    "crumbs": [
      "PyPotteryInk",
      "API Documentation"
    ]
  },
  {
    "objectID": "pypotteryink/api.html#process-folder-metrics",
    "href": "pypotteryink/api.html#process-folder-metrics",
    "title": "API Documentation",
    "section": "Process Folder Metrics",
    "text": "Process Folder Metrics\ndef process_folder_metrics(\n    input_folder: str,\n    model_stats: dict,\n    file_extensions: tuple = ('.jpg', '.jpeg', '.png')\n) -&gt; None\nBatch processes a folder of drawings to align their metrics with reference statistics.\n\nParameters\n\ninput_folder\n\nDirectory containing drawings to process\n\nmodel_stats\n\nReference statistics from DatasetAnalyzer\n\nfile_extensions\n\nSupported file types",
    "crumbs": [
      "PyPotteryInk",
      "API Documentation"
    ]
  },
  {
    "objectID": "pypotteryink/api.html#apply-recommended-adjustments",
    "href": "pypotteryink/api.html#apply-recommended-adjustments",
    "title": "API Documentation",
    "section": "Apply Recommended Adjustments",
    "text": "Apply Recommended Adjustments\ndef apply_recommended_adjustments(\n    image: Union[str, Image.Image],\n    model_stats: dict,\n    verbose: bool = True\n) -&gt; Image.Image\nAutomatically adjusts a drawing based on statistical analysis.\n\nParameters\n\nimage\n\nDrawing to adjust\n\nmodel_stats\n\nReference statistics\n\nverbose\n\nPrint adjustment details\n\n\n\n\nAdjustments Applied\n\nContrast normalization\nBrightness alignment\nStandard deviation correction\nDynamic range optimization\n\n\n\nExamples\nadjusted = apply_recommended_adjustments(\n    \"drawing.jpg\",\n    reference_stats,\n    verbose=True\n)",
    "crumbs": [
      "PyPotteryInk",
      "API Documentation"
    ]
  },
  {
    "objectID": "pypotteryink/api.html#check-image-quality",
    "href": "pypotteryink/api.html#check-image-quality",
    "title": "API Documentation",
    "section": "Check Image Quality",
    "text": "Check Image Quality\ndef check_image_quality(\n    image: Union[str, Image.Image],\n    model_stats: dict\n) -&gt; dict\nEvaluates a drawing against reference metrics to identify needed adjustments.\n\nReturns\nReturns a dictionary containing:\n\nmetrics: Current image measurements\nrecommendations: List of suggested adjustments\nis_compatible: Boolean indicating if adjustments needed\n\n\n\nExamples\ncheck = check_image_quality(\"new_drawing.jpg\", reference_stats)\nif not check['is_compatible']:\n    print(\"Adjustments needed:\", check['recommendations'])",
    "crumbs": [
      "PyPotteryInk",
      "API Documentation"
    ]
  },
  {
    "objectID": "pypotteryink/api.html#visualize-metrics-change",
    "href": "pypotteryink/api.html#visualize-metrics-change",
    "title": "API Documentation",
    "section": "Visualize Metrics Change",
    "text": "Visualize Metrics Change\ndef visualize_metrics_change(\n    original_metrics: dict,\n    adjusted_metrics: dict,\n    model_stats: dict,\n    metrics_to_plot: Optional[List[str]] = None,\n    save: bool = False\n) -&gt; None\nCreates detailed visualizations comparing original and adjusted metrics against reference distributions.\n\nParameters\n\noriginal_metrics\n\nMetrics before adjustment\n\nadjusted_metrics\n\nMetrics after adjustment\n\nmodel_stats\n\nReference statistics\n\nmetrics_to_plot\n\nSpecific metrics to visualize\n\nsave\n\nSave plot to file\n\n\n\n\nExamples\nvisualize_metrics_change(\n    original_metrics,\n    adjusted_metrics,\n    reference_stats,\n    metrics_to_plot=['contrast_ratio', 'mean', 'std']\n)",
    "crumbs": [
      "PyPotteryInk",
      "API Documentation"
    ]
  },
  {
    "objectID": "pypotteryink/model_zoo.html",
    "href": "pypotteryink/model_zoo.html",
    "title": "PyPotteryInk Model Zoo",
    "section": "",
    "text": "version 2.0.0",
    "crumbs": [
      "PyPotteryInk",
      "PyPotteryInk Model Zoo"
    ]
  },
  {
    "objectID": "pypotteryink/model_zoo.html#overview",
    "href": "pypotteryink/model_zoo.html#overview",
    "title": "PyPotteryInk Model Zoo",
    "section": "Overview",
    "text": "Overview\nThis page lists the available pre-trained models for PyPotteryInk. Each model is show specific pros and cons. You can use these models directly or fine-tune them for your specific needs.",
    "crumbs": [
      "PyPotteryInk",
      "PyPotteryInk Model Zoo"
    ]
  },
  {
    "objectID": "pypotteryink/model_zoo.html#benchmark-image",
    "href": "pypotteryink/model_zoo.html#benchmark-image",
    "title": "PyPotteryInk Model Zoo",
    "section": "Benchmark image",
    "text": "Benchmark image\nThe benchmark image contains a variety of images and styles for testing each model. It can be used to quickly assess the quality of the output. As the library will be used for a variety of different styles and morphologies, new images will be added to the benchmark images.",
    "crumbs": [
      "PyPotteryInk",
      "PyPotteryInk Model Zoo"
    ]
  },
  {
    "objectID": "pypotteryink/model_zoo.html#available-models",
    "href": "pypotteryink/model_zoo.html#available-models",
    "title": "PyPotteryInk Model Zoo",
    "section": "Available Models",
    "text": "Available Models\n\n10k\nDescription: The base model trained on a diverse dataset of 492 archaeological drawings from multiple contexts including Casinalbo, Montale, Monte Croce Guardia, and Monte Cimino sites.\n\nTraining Data: 492 paired drawings\nResolution: 512√ó512 pixels\nTraining Steps: 10,000\nBest For: General purpose archaeological drawing inking, starting point for fine-tuning\n\nParameters used for training:\n\n\n\nParameter\n10k\n\n\n\n\nadam_beta1\n0.9\n\n\nadam_beta2\n0.999\n\n\nadam_epsilon\n0.00000001\n\n\nadam_weight_decay\n0.01\n\n\nallow_tf32\nfalse\n\n\ncheckpointing_steps\n500\n\n\ndataloader_num_workers\n0\n\n\nenable_xformers_memory_efficient_attention\ntrue\n\n\neval_freq\n100\n\n\ngan_disc_type\n‚Äúvagan_clip‚Äù\n\n\ngan_loss_type\n‚Äúmultilevel_sigmoid_s‚Äù\n\n\ngradient_accumulation_steps\n1\n\n\ngradient_checkpointing\nfalse\n\n\nlambda_clipsim\n5\n\n\nlambda_gan\n0.5\n\n\nlambda_l2\n1\n\n\nlambda_lpips\n5\n\n\nlearning_rate\n0.000005\n\n\nlora_rank_unet\n8\n\n\nlora_rank_vae\n4\n\n\nlr_num_cycles\n1\n\n\nlr_power\n1\n\n\nlr_scheduler\n‚Äúconstant‚Äù\n\n\nlr_warmup_steps\n500\n\n\nmax_grad_norm\n1\n\n\nmax_train_steps\n10,000\n\n\nmixed_precision\n‚Äúno‚Äù\n\n\nnum_samples_eval\n100\n\n\nnum_training_epochs\n1\n\n\npretrained_model_name_or_path\n‚Äústabilityai/sd-turbo‚Äù\n\n\nresolution\n512\n\n\nset_grads_to_none\nfalse\n\n\ntest_image_prep\n‚Äúresized_crop_512‚Äù\n\n\ntrack_val_fid\ntrue\n\n\ntrain_batch_size\n2\n\n\ntrain_image_prep\n‚Äúresized_crop_512‚Äù\n\n\nviz_freq\n25\n\n\n\nAuthor: Lorenzo Cardarelli\n\n\n\nModels\n\n\n\nBenchmark\n\n\n\n\n6h-MCG\nDescription: Fine-tuned model specialized for Monte Croce Guardia style pottery drawings. Optimized for high-detail preservation and consistent stippling patterns.\n\nTraining Data: 9 paired drawings from Monte Croce Guardia\nBase Model: 10k Base Model\nResolution: 512√ó512 pixels\nTraining Steps: 600\nBest For: Middle Bronze Age / Recent Bronze Age pottery\n\nParameters used for training:\n\n\n\nParameter\n6h-MCG\n\n\n\n\nadam_beta1\n0.9\n\n\nadam_beta2\n0.999\n\n\nadam_epsilon\n0.00000001\n\n\nadam_weight_decay\n0.01\n\n\nallow_tf32\nfalse\n\n\ncheckpointing_steps\n100\n\n\ndataloader_num_workers\n4\n\n\nenable_xformers_memory_efficient_attention\ntrue\n\n\neval_freq\n100\n\n\ngan_disc_type\n‚Äúvagan_clip‚Äù\n\n\ngan_loss_type\n‚Äúmultilevel_sigmoid_s‚Äù\n\n\ngradient_accumulation_steps\n4\n\n\ngradient_checkpointing\nfalse\n\n\nlambda_clipsim\n3\n\n\nlambda_gan\n0.9\n\n\nlambda_l2\n1\n\n\nlambda_lpips\n10\n\n\nlearning_rate\n0.00001\n\n\nlora_rank_unet\n128\n\n\nlora_rank_vae\n48\n\n\nlr_num_cycles\n1\n\n\nlr_power\n1\n\n\nlr_scheduler\n‚Äúconstant‚Äù\n\n\nlr_warmup_steps\n200\n\n\nmax_grad_norm\n1\n\n\nmax_train_steps\n600\n\n\nmixed_precision\n‚Äúno‚Äù\n\n\nnum_samples_eval\n100\n\n\nnum_training_epochs\n1\n\n\npretrained_model_name_or_path\n./10k.pkl\n\n\nresolution\n512\n\n\nset_grads_to_none\nfalse\n\n\ntest_image_prep\n‚Äúresized_crop_512‚Äù\n\n\ntrack_val_fid\ntrue\n\n\ntrain_batch_size\n1\n\n\ntrain_image_prep\n‚Äúresized_crop_512‚Äù\n\n\nviz_freq\n50\n\n\n\nAuthor: Lorenzo Cardarelli\n\n\n\nModels\n\n\n\nBenchmark\n\n\n\n\n6h-MC\nDescription: Fine-tuned model specialized for Monte Cimino style pottery drawings. Optimized for high-detail preservation and engraved decoration.\n\nTraining Data: 15 paired drawings from Monte Cimino\nBase Model: 10k Base Model\nResolution: 512√ó512 pixels\nTraining Steps: 600\nBest For: Recent Bronze Age pottery / Final Bronze Age / Historic Age\n\nParameters used for training:\n\n\n\nParameter\n6h-MC\n\n\n\n\nadam_beta1\n0.9\n\n\nadam_beta2\n0.999\n\n\nadam_epsilon\n0.00000001\n\n\nadam_weight_decay\n0.01\n\n\nallow_tf32\nfalse\n\n\ncheckpointing_steps\n100\n\n\ndataloader_num_workers\n4\n\n\nenable_xformers_memory_efficient_attention\ntrue\n\n\neval_freq\n100\n\n\ngan_disc_type\n‚Äúvagan_clip‚Äù\n\n\ngan_loss_type\n‚Äúmultilevel_sigmoid_s‚Äù\n\n\ngradient_accumulation_steps\n4\n\n\ngradient_checkpointing\nfalse\n\n\nlambda_clipsim\n3\n\n\nlambda_gan\n0.9\n\n\nlambda_l2\n1\n\n\nlambda_lpips\n10\n\n\nlearning_rate\n0.00001\n\n\nlora_rank_unet\n256\n\n\nlora_rank_vae\n48\n\n\nlr_num_cycles\n1\n\n\nlr_power\n1\n\n\nlr_scheduler\n‚Äúcosine‚Äù\n\n\nlr_warmup_steps\n200\n\n\nmax_grad_norm\n1\n\n\nmax_train_steps\n600\n\n\nmixed_precision\n‚Äúno‚Äù\n\n\nnum_samples_eval\n100\n\n\nnum_training_epochs\n1\n\n\npretrained_model_name_or_path\n./10k.pkl\n\n\nresolution\n512\n\n\nset_grads_to_none\nfalse\n\n\ntest_image_prep\n‚Äúresized_crop_512‚Äù\n\n\ntrack_val_fid\ntrue\n\n\ntrain_batch_size\n1\n\n\ntrain_image_prep\n‚Äúresized_crop_512‚Äù\n\n\nviz_freq\n50\n\n\n\nAuthor: Lorenzo Cardarelli\n\n\n\nModels\n\n\n\nBenchmark\n\n\n\n\n4h-PAINT\nDescription: Fine-tuned model specialized for painted decoration and historical pottery.\n\nTraining Data: 15 paired drawings from Late Bronze Age / Early Iron Age of Southern Italy\nBase Model: 6h-MC\nResolution: 512√ó512 pixels\nTraining Steps: 400\nBest For: Historic Age / Painted Pottery (No shadows!)\n\nParameters used for training:\n\n\n\nParameter\n4h-PAINT\n\n\n\n\nadam_beta1\n0.9\n\n\nadam_beta2\n0.999\n\n\nadam_epsilon\n0.00000001\n\n\nadam_weight_decay\n0.01\n\n\nallow_tf32\nfalse\n\n\ncheckpointing_steps\n100\n\n\ndataloader_num_workers\n4\n\n\nenable_xformers_memory_efficient_attention\ntrue\n\n\neval_freq\n100\n\n\ngan_disc_type\n‚Äúvagan_clip‚Äù\n\n\ngan_loss_type\n‚Äúmultilevel_sigmoid_s‚Äù\n\n\ngradient_accumulation_steps\n4\n\n\ngradient_checkpointing\nfalse\n\n\nlambda_clipsim\n3\n\n\nlambda_gan\n0.9\n\n\nlambda_l2\n1\n\n\nlambda_lpips\n10\n\n\nlearning_rate\n0.00001\n\n\nlora_rank_unet\n256\n\n\nlora_rank_vae\n48\n\n\nlr_num_cycles\n1\n\n\nlr_power\n1\n\n\nlr_scheduler\n‚Äúcosine‚Äù\n\n\nlr_warmup_steps\n200\n\n\nmax_grad_norm\n1\n\n\nmax_train_steps\n400\n\n\nmixed_precision\n‚Äúno‚Äù\n\n\nnum_samples_eval\n100\n\n\nnum_training_epochs\n1\n\n\npretrained_model_name_or_path\n./6h-MC.pkl\n\n\nresolution\n512\n\n\nset_grads_to_none\nfalse\n\n\ntest_image_prep\n‚Äúresized_crop_512‚Äù\n\n\ntrack_val_fid\ntrue\n\n\ntrain_batch_size\n1\n\n\ntrain_image_prep\n‚Äúresized_crop_512‚Äù\n\n\nviz_freq\n50\n\n\n\nAuthor: Lorenzo Cardarelli, Elisa Pizzuti\n\n\n\nModels\n\n\n\nBenchmark\n\n\n\n\n5h-PAPERGRID\nDescription: Fine-tuned model specialized for papergrid pottery.\n\nTraining Data: 15 paired drawings from Middle Bronze Age of Northern Italy\nBase Model: 6h-MC\nResolution: 512√ó512 pixels\nTraining Steps: 400\nBest For: Papergrid Pottery (No shadows!)\n\nParameters used for training:\n\n\n\nParameter\n5h-PAPERGRID\n\n\n\n\nadam_beta1\n0.9\n\n\nadam_beta2\n0.999\n\n\nadam_epsilon\n0.00000001\n\n\nadam_weight_decay\n0.01\n\n\nallow_tf32\nfalse\n\n\ncheckpointing_steps\n100\n\n\ndataloader_num_workers\n4\n\n\nenable_xformers_memory_efficient_attention\ntrue\n\n\neval_freq\n100\n\n\ngan_disc_type\n‚Äúvagan_clip‚Äù\n\n\ngan_loss_type\n‚Äúmultilevel_sigmoid_s‚Äù\n\n\ngradient_accumulation_steps\n4\n\n\ngradient_checkpointing\nfalse\n\n\nlambda_clipsim\n3\n\n\nlambda_gan\n0.9\n\n\nlambda_l2\n1\n\n\nlambda_lpips\n10\n\n\nlearning_rate\n0.00001\n\n\nlora_rank_unet\n256\n\n\nlora_rank_vae\n48\n\n\nlr_num_cycles\n1\n\n\nlr_power\n1\n\n\nlr_scheduler\n‚Äúcosine‚Äù\n\n\nlr_warmup_steps\n200\n\n\nmax_grad_norm\n1\n\n\nmax_train_steps\n400\n\n\nmixed_precision\n‚Äúno‚Äù\n\n\nnum_samples_eval\n100\n\n\nnum_training_epochs\n1\n\n\npretrained_model_name_or_path\n./6h-MC.pkl\n\n\nresolution\n512\n\n\nset_grads_to_none\nfalse\n\n\ntest_image_prep\n‚Äúresized_crop_512‚Äù\n\n\ntrack_val_fid\ntrue\n\n\ntrain_batch_size\n1\n\n\ntrain_image_prep\n‚Äúresized_crop_512‚Äù\n\n\nviz_freq\n50\n\n\n\nAuthor: Lorenzo Cardarelli, Federico Erbetti\n\n\n\nModels",
    "crumbs": [
      "PyPotteryInk",
      "PyPotteryInk Model Zoo"
    ]
  },
  {
    "objectID": "pypotteryink/version_history.html",
    "href": "pypotteryink/version_history.html",
    "title": "Version History",
    "section": "",
    "text": "üöÄ A PyPotteryInk major release üöÄ\nKey Features:\n\nFlask Web Interface: New user-friendly web interface with multiple tabs:\n\nHardware Check: Verify system compatibility\nModel Diagnostics: Preview processing with different settings\nPreprocessing: Analyze and optimize images before processing\nBatch Processing: Process multiple images with progress tracking",
    "crumbs": [
      "PyPotteryInk",
      "Version History"
    ]
  },
  {
    "objectID": "pypotteryink/version_history.html#latest-release",
    "href": "pypotteryink/version_history.html#latest-release",
    "title": "Version History",
    "section": "",
    "text": "üöÄ A PyPotteryInk major release üöÄ\nKey Features:\n\nFlask Web Interface: New user-friendly web interface with multiple tabs:\n\nHardware Check: Verify system compatibility\nModel Diagnostics: Preview processing with different settings\nPreprocessing: Analyze and optimize images before processing\nBatch Processing: Process multiple images with progress tracking",
    "crumbs": [
      "PyPotteryInk",
      "Version History"
    ]
  },
  {
    "objectID": "pypotteryink/version_history.html#version-history",
    "href": "pypotteryink/version_history.html#version-history",
    "title": "Version History",
    "section": "Version History",
    "text": "Version History\n\nVersion 1.0.0 (September 2025)\nüöÄ A PyPotteryInk major release üöÄ\nKey Features:\n\nMulti-GPU Support: Added support for Apple Silicon (M1/M2/M3) GPUs via Metal Performance Shaders\nGradio Web Interface: New user-friendly web interface with multiple tabs:\n\nHardware Check: Verify system compatibility\nModel Diagnostics: Preview processing with different settings\nPreprocessing: Analyze and optimize images before processing\nBatch Processing: Process multiple images with progress tracking\n\nAutomated Installation: One-click installation scripts for all platforms\nImproved Compatibility: Fixed compatibility issues with newest packages\nStatistics Visualization: New detailed statistics analysis with:\n\nSummary tables showing all key metrics\nInteractive distribution plots\nHistogram and KDE visualizations\nBox plots for metric overview\n\nAdvanced Export Options (Experimental):\n\nElement extraction: Automatically identify and extract individual pottery elements\nSVG export: Convert processed images to scalable vector graphics for publication\n\n\nwith contributions from Francesco di Filippo and Enzo Cocca\n\n\nVersion 0.0.3 (July 2025)\nUpdate to the PyPotteryInk package, with a few improvements\nKey Features:\n\nüìå Added new model 6h-MC model as default üìå\nAdded a test_imgto visualize the performance of each model\nReworking of the test.py module: now it test the library on the test_img\nAdded downscaling options in process_single_image and process_folder\n\nModels:\n\nFine-tuned example for Monte Cimino assemblage (6h-MC)\nFine-tuned model for historical and painted pottery (4h-PAINT)\n\n\n\nVersion 0.0.2 (April 2025)\nA little update to the PyPotteryInk package, with a few bug fixes and improvements.\nKey Features:\n\nAdded an AI disclosure reminder when running the process_folder function\nAdded a Google Colab notebook for easy testing of the package\nFixed some errors in the documentation\n\n\n\nVersion 0.0.1 (January 2025)\nInitial public release of PyPotteryInk.\nKey Features:\n\nImage-to-image translation using pix2pix-turbo architecture\nAdaptive patch-based processing for high-resolution drawings\nComprehensive preprocessing and postprocessing tools\nWeb documentation\n\nModels:\n\nBase model trained on 500 protohistoric pottery drawings (10k)\nFine-tuned example for Monte Croce Guardia assemblage (6h-MCG)",
    "crumbs": [
      "PyPotteryInk",
      "Version History"
    ]
  },
  {
    "objectID": "pypotterylens/installation.html",
    "href": "pypotterylens/installation.html",
    "title": "Installation",
    "section": "",
    "text": "version 0.1.0",
    "crumbs": [
      "PyPotteryLens",
      "Installation"
    ]
  },
  {
    "objectID": "pypotterylens/installation.html#requirements",
    "href": "pypotterylens/installation.html#requirements",
    "title": "Installation",
    "section": "Requirements",
    "text": "Requirements\nBefore installing PyPotteryLens, make sure you have:\n\nPython 3.12 installed on your system",
    "crumbs": [
      "PyPotteryLens",
      "Installation"
    ]
  },
  {
    "objectID": "pypotterylens/installation.html#automated-installation",
    "href": "pypotterylens/installation.html#automated-installation",
    "title": "Installation",
    "section": "Automated Installation",
    "text": "Automated Installation\nAutomated installation is the quickest and easiest way to get PyPotteryLens running. The provided scripts will:\n\n‚úÖ Create a Python virtual environment\n‚úÖ Automatically install all dependencies\n‚úÖ Start the application\n\n\nWindows\nDouble click on the PyPotteryLens_WIN.bat file.\nThe script will automatically perform the following steps:\n\nCheck for Python on the system\nCreate the .venv virtual environment (if it doesn‚Äôt exist)\nActivate the virtual environment\nInstall/upgrade pip\nInstall dependencies from requirements.txt\nStart the Flask server\n\n\n\n\n\n\n\nüí° Tip\n\n\n\nOn first run, dependency installation may take a few minutes. Subsequent runs will be much faster!\n\n\n\n\nLinux / macOS\n\nOpen the Terminal in the project directory\nMake the script executable (first time only):\n\nchmod +x PyPotteryLens_UNIX.sh\n\nRun the script:\n\n./PyPotteryLens_UNIX.sh\nThe script will automatically:\n\nCheck for Python 3 on the system\nCreate the .venv virtual environment (if it doesn‚Äôt exist)\nActivate the virtual environment\nInstall/upgrade pip\nInstall dependencies from requirements.txt\nStart the Flask server\n\n\n\n\n\n\n\nüìå Note\n\n\n\nTo stop the server, press Ctrl+C in the terminal.",
    "crumbs": [
      "PyPotteryLens",
      "Installation"
    ]
  },
  {
    "objectID": "pypotterylens/installation.html#manual-installation",
    "href": "pypotterylens/installation.html#manual-installation",
    "title": "Installation",
    "section": "Manual Installation",
    "text": "Manual Installation\nIf you prefer full control over the installation process, you can follow these manual steps:\n\n1. Create a Virtual Environment\nIt is strongly recommended to use a virtual environment to isolate project dependencies:\n\nWindowsLinux / macOS\n\n\npython -m venv .venv\n.venv\\Scripts\\activate\n\n\npython3 -m venv .venv\nsource .venv/bin/activate\n\n\n\n\n\n2. Upgrade pip\nUpgrade pip to the latest available version:\npython -m pip install --upgrade pip\n\n\n3. Install Dependencies\nInstall all required dependencies from the requirements.txt file:\npip install -r requirements.txt\n\n\n\n\n\n\n‚ö†Ô∏è Warning\n\n\n\nMake sure you are in the project‚Äôs root directory where the requirements.txt file is located.\n\n\n\n\n4. Start the Application\nOnce installation is complete, start the application with:\npython app.py",
    "crumbs": [
      "PyPotteryLens",
      "Installation"
    ]
  },
  {
    "objectID": "pypotterylens/installation.html#installation-verification",
    "href": "pypotterylens/installation.html#installation-verification",
    "title": "Installation",
    "section": "Installation Verification",
    "text": "Installation Verification\nTo verify that everything was installed correctly:\n\nThe application should start without errors\nYou should see a confirmation message in the terminal\nOpening your browser at the indicated URL should display the PyPotteryLens interface",
    "crumbs": [
      "PyPotteryLens",
      "Installation"
    ]
  },
  {
    "objectID": "pypotterylens/installation.html#troubleshooting",
    "href": "pypotterylens/installation.html#troubleshooting",
    "title": "Installation",
    "section": "Troubleshooting",
    "text": "Troubleshooting\n\nPython not found\nIf you receive an error indicating that Python is not installed:\n\nWindows: Download Python from python.org and make sure to check ‚ÄúAdd Python to PATH‚Äù during installation\nLinux: Install Python using your distribution‚Äôs package manager (e.g., sudo apt install python3)\nmacOS: Install Python via Homebrew with brew install python3\n\n\n\nDependency installation errors\nIf dependency installation fails:\n\nMake sure you have an active internet connection\nTry upgrading pip: python -m pip install --upgrade pip\nInstall dependencies one at a time to identify which package is causing issues",
    "crumbs": [
      "PyPotteryLens",
      "Installation"
    ]
  },
  {
    "objectID": "pypotterylens/version_history.html",
    "href": "pypotterylens/version_history.html",
    "title": "Version History",
    "section": "",
    "text": "Key Features:\n\nMajor architectural change: Migrated from Gradio to Flask web framework\nProject Management System: Introduced project-based workflow with dedicated workspaces\nModern Web Interface: Native HTML/CSS/JavaScript frontend with improved UX\nRESTful API: Full API for programmatic access and future integrations\nEnhanced Canvas Editor: Improved annotation tools with better performance\nReal-time Progress Tracking: Live updates for long-running operations\nAuto-save Everything: Automatic persistence for all user changes\nWorkflow Status Tracking: Visual indicators for project completion stages\nMulti-project Support: Work on multiple datasets simultaneously\nImproved Error Handling: Better user feedback and error recovery",
    "crumbs": [
      "PyPotteryLens",
      "Version History"
    ]
  },
  {
    "objectID": "pypotterylens/version_history.html#v0.1.0",
    "href": "pypotterylens/version_history.html#v0.1.0",
    "title": "Version History",
    "section": "",
    "text": "Initial release of documentation.\nBasic project management and PDF processing.\nIntegration of CV models for mask extraction.",
    "crumbs": [
      "PyPotteryLens",
      "Version History"
    ]
  },
  {
    "objectID": "pypotteryscan/installation.html",
    "href": "pypotteryscan/installation.html",
    "title": "Installation",
    "section": "",
    "text": "version 0.2.0",
    "crumbs": [
      "PyPotteryScan",
      "Installation"
    ]
  },
  {
    "objectID": "pypotteryscan/installation.html#requirements",
    "href": "pypotteryscan/installation.html#requirements",
    "title": "Installation",
    "section": "Requirements",
    "text": "Requirements\nBefore installing PyPotteryScan, make sure you have:\n\nPython 3.12 installed on your system\nA NVIDIA GPU with CUDA support",
    "crumbs": [
      "PyPotteryScan",
      "Installation"
    ]
  },
  {
    "objectID": "pypotteryscan/installation.html#automated-installation",
    "href": "pypotteryscan/installation.html#automated-installation",
    "title": "Installation",
    "section": "Automated Installation",
    "text": "Automated Installation\nAutomated installation is the quickest and easiest way to get PyPotteryScan running. The provided scripts will:\n\n‚úÖ Create a Python virtual environment\n‚úÖ Automatically install all dependencies\n‚úÖ Start the application\n\n\nWindows\nDouble click on the PyPotteryScan_WIN.bat file.\nThe script will automatically perform the following steps:\n\nCheck for Python on the system\nCreate the .venv virtual environment (if it doesn‚Äôt exist)\nActivate the virtual environment\nInstall/upgrade pip\nInstall dependencies from requirements.txt\nStart the Flask server at http://localhost:5002\n\n\n\n\n\n\n\nüí° Tip\n\n\n\nOn first run, dependency installation may take a few minutes. Subsequent runs will be much faster!\n\n\n\n\nLinux / macOS\n\nOpen the Terminal in the project directory\nMake the script executable (first time only):\n\nchmod +x PyPotteryScan_UNIX.sh\n\nRun the script:\n\n./PyPotteryScan_UNIX.sh\nThe script will automatically:\n\nCheck for Python 3 on the system\nCreate the .venv virtual environment (if it doesn‚Äôt exist)\nActivate the virtual environment\nInstall/upgrade pip\nInstall dependencies from requirements.txt\nStart the Flask server at http://127.0.0.1:5002\n\n\n\n\n\n\n\nüìå Note\n\n\n\nTo stop the server, press Ctrl+C in the terminal.",
    "crumbs": [
      "PyPotteryScan",
      "Installation"
    ]
  },
  {
    "objectID": "pypotteryscan/installation.html#manual-installation",
    "href": "pypotteryscan/installation.html#manual-installation",
    "title": "Installation",
    "section": "Manual Installation",
    "text": "Manual Installation\nIf you prefer full control over the installation process, you can follow these manual steps:\n\n1. Create a Virtual Environment\nIt is strongly recommended to use a virtual environment to isolate project dependencies:\n\nWindowsLinux / macOS\n\n\npython -m venv .venv\n.venv\\Scripts\\activate\n\n\npython3 -m venv .venv\nsource .venv/bin/activate\n\n\n\n\n\n2. Upgrade pip\nUpgrade pip to the latest available version:\npython -m pip install --upgrade pip\n\n\n3. Install Dependencies\nInstall all required dependencies from the requirements.txt file:\npip install -r requirements.txt\n\n\n\n\n\n\n‚ö†Ô∏è Warning\n\n\n\nMake sure you are in the project‚Äôs root directory where the requirements.txt file is located.\n\n\n\n\n4. Start the Application\nOnce installation is complete, start the application with:\npython app.py\nThe application will be available at:\n\n\n\n\n\n\nüåê Application URL\n\n\n\nhttp://localhost:5002",
    "crumbs": [
      "PyPotteryScan",
      "Installation"
    ]
  },
  {
    "objectID": "pypotteryscan/installation.html#installation-verification",
    "href": "pypotteryscan/installation.html#installation-verification",
    "title": "Installation",
    "section": "Installation Verification",
    "text": "Installation Verification\nTo verify that everything was installed correctly:\n\nThe application should start without errors\nYou should see a confirmation message in the terminal\nOpening your browser at http://localhost:5002 should display the PyPotteryScan interface",
    "crumbs": [
      "PyPotteryScan",
      "Installation"
    ]
  },
  {
    "objectID": "pypotteryscan/installation.html#troubleshooting",
    "href": "pypotteryscan/installation.html#troubleshooting",
    "title": "Installation",
    "section": "Troubleshooting",
    "text": "Troubleshooting\n\nPython not found\nIf you receive an error indicating that Python is not installed:\n\nWindows: Download Python from python.org and make sure to check ‚ÄúAdd Python to PATH‚Äù during installation\nLinux: Install Python using your distribution‚Äôs package manager (e.g., sudo apt install python3)\nmacOS: Install Python via Homebrew with brew install python3\n\n\n\nDependency installation errors\nIf dependency installation fails:\n\nMake sure you have an active internet connection\nTry upgrading pip: python -m pip install --upgrade pip\nInstall dependencies one at a time to identify which package is causing issues\n\n\n\nPort 5002 already in use\nIf port 5002 is already occupied by another application, you can:\n\nClose the application using the port\nOr modify the port in the app.py file",
    "crumbs": [
      "PyPotteryScan",
      "Installation"
    ]
  },
  {
    "objectID": "pypotteryscan/installation.html#updating",
    "href": "pypotteryscan/installation.html#updating",
    "title": "Installation",
    "section": "Updating",
    "text": "Updating\nTo update PyPotteryScan to the latest version:\n\nDownload the latest version of the code\nActivate the virtual environment\nUpdate dependencies:\n\npip install -r requirements.txt --upgrade",
    "crumbs": [
      "PyPotteryScan",
      "Installation"
    ]
  },
  {
    "objectID": "pypotteryscan/version_history.html#v0.2.0-initial-release---december-2025",
    "href": "pypotteryscan/version_history.html#v0.2.0-initial-release---december-2025",
    "title": "Version History",
    "section": "v0.2.0 (Initial Release) - (December 2025)",
    "text": "v0.2.0 (Initial Release) - (December 2025)\nüöÄ A PyPotteryScan major release üöÄ\n\nInitial release of PyPotteryScan.",
    "crumbs": [
      "PyPotteryScan",
      "Version History"
    ]
  },
  {
    "objectID": "pypotterylens/version_history.html#latest-release",
    "href": "pypotterylens/version_history.html#latest-release",
    "title": "Version History",
    "section": "",
    "text": "Key Features:\n\nMajor architectural change: Migrated from Gradio to Flask web framework\nProject Management System: Introduced project-based workflow with dedicated workspaces\nModern Web Interface: Native HTML/CSS/JavaScript frontend with improved UX\nRESTful API: Full API for programmatic access and future integrations\nEnhanced Canvas Editor: Improved annotation tools with better performance\nReal-time Progress Tracking: Live updates for long-running operations\nAuto-save Everything: Automatic persistence for all user changes\nWorkflow Status Tracking: Visual indicators for project completion stages\nMulti-project Support: Work on multiple datasets simultaneously\nImproved Error Handling: Better user feedback and error recovery",
    "crumbs": [
      "PyPotteryLens",
      "Version History"
    ]
  },
  {
    "objectID": "pypotterylens/version_history.html#version-history",
    "href": "pypotterylens/version_history.html#version-history",
    "title": "Version History",
    "section": "Version History",
    "text": "Version History\n\nVersion 0.1.3 (August 2025)\nKey Features:\n\nMinor bug fixes and performance improvements\n\n\n\nVersion 0.1.0 (April 2025)\nKey Features:\n\nInitial release of documentation.\nBasic project management and PDF processing.\nIntegration of CV models for mask extraction.",
    "crumbs": [
      "PyPotteryLens",
      "Version History"
    ]
  }
]